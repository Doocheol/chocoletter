# ✏️ TIL (Today I Learned)

## 2025.01.24 (금)
### ✅ TO DO
- 카카오톡 발송 딜러사 컨텍
- 채팅 시스템 설계
- 카프카 개념 공부

### 🔥 What I Learned
- 📌 **Kafka란 ?**
    - Apache Software Foundation의 Scalar 언어로 된 오픈 소스 메시지 브로커 프로젝트
        - 메세지 브로커라는 것은 특정한 리소스에서 다른 쪽에 있는 리소스 또는 서비스 시스템으로 메세지를 전달할 때 사용하는 서버
    - Open Source Message Broker Project
    - 링크드인(Linked-in)에서 개발, 2011년 오픈 소스화
        - 2014년 11월 링크드인에서 Kafka를 개발하던 엔지니어들이 Kafka 개발에 집중하기 위해 Confluent라는 회사 창립
    - 실시간 데이터 피드를 관리하기 위해 통일된 높은 처리량, 낮은 지연 시간을 지닌 플랫폼 제공
    - Apple, Netflix, Shopify, Yelp, Kakao, New York Times, Cisco, Ebay, Paypal, Hyperledger Fabric, Uber, salesforce.com 등이 사용
    - End-to-End 연결 방식의 아키텍처
    - 데이터 연동의 복잡성 증가 (HW, 운영체제, 장애 등)
    - 서로 다른 데이터 Pipeline 연결 구조 → MySQL에서 전달할 수 있는 시스템을 Oracle에서 사용할 수 없다
    - 확장이 어려운 구조

    **즉, 카프카가 탄생하게 된 배경은 이런 문제점을 해결하기 위해서 모든 시스템으로 데이터를 실시간 전송하여 처리할 수 있는 시스템, 데이터가 많아지더라도 확장이 용이한 시스템을 요구하게 된 것이다 !**

    카프카를 가운데 두면 아래와 같은 이점이 생기게 되는 것이다 !

    - Producer / Consumer 분리
    - 메세지를 여러 Consumer에게 허용
    - 높은 처리량을 위한 메세지 최적화
    - Scale-out 가능
    - Eco-system → 카프카로 지금처럼 프로듀서, 컨슈머와 같이 보내고 받는 용도만 사용되는 것이 아니라 데이터 스트리밍 서비스를 해준다던가 관계형 데이터베이스처럼 SQL과 같은 문법을 제공해주면서 쉽게 이전에 썼던 스토리징 서비스와 연결이 된다던가 하는 식의 시나리오를 생각해볼 수 있다.

- 📌 **카프카 생태계**

    - 토픽 → RDBMS의 테이블과 같은 개념 / 구분하고자 하는 데이터
        - 토픽 안에는 한개 이상의 파티션을 가지게 됨
        - 파티션은 큐와 같은 FIFO 구조를 가짐
    - 큐에 데이터를 보내는 것은 프로듀서, 데이터를 가져가는 것은 컨슈머
    - 토픽 간의 데이터 이동이 필요할 때 사용하는 것은 카프카 스트림즈 라이브리러리
    - 위 구조에서 프로듀서, 커넥트, 컨슈머, 스트림즈는 아파치 카프카가 기본적으로 제공하는 공식 자바 기반 라이브러리
    - 소스 커넥트 → 데이터베이스나 데이터 저장소에서 데이터를 가져와서 토픽에 넣는 역할, 즉 프로듀서가 하는 역할을 함
    - 싱크 커넥트 → 타겟 애플리케이션을도 데이터를 보내는 역할, 즉 컨슈머가 하는 역할을 함

- 📌 **토픽과 파티션**
    - `토픽` 은 카프카에서 데이터를 구분하기 위해 사용하는 단위
    - 이벤트가 관련된 것들끼리 모여서 Stream을 이루게 되고, 이게 카프카에 저장될 때 Topic의 이름으로 저장된다.
    - 토픽이 카프카에서 일종의 논리적인 개념이라면, 파티션은 토픽에 속한 레코드들이 실제 저장소에 저장하는 가장 작은 단위이다.
    - `파티션` 은 카프카의 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭
    - 즉, 파티션과 컨슈머는 1:1 매핑
    - 컨슈머의 처리량이 한정된 상황에서 많은 레코드를 병렬로 처리하는 가장 좋은 방법은 컨슈머의 개수를 늘려 스케일 아웃하는 것이다.
    - 파티션 개수를 줄이는 것은 지원하지 않는다. 그러므로 파티션을 늘리는 작업을 할 때는 신중히 파티션 개수를 정해야 한다.

## 2025.01.23 (목)
### ✅ TO DO
- 맡은 API 개발 끝내기
- 카카오톡 알림톡 전송 관련 레퍼런스 찾고 세팅하기
- 딜러사 문의 넣기


## 2025.01.22 (수)
### ✅ TO DO
- 맡은 API 구현
- path varible로 받는 ID를 디코딩 할 수 있는 사용자 어노테이션 구현

### 🔥 What I Learned
- **📌  Custom Annotation**
    - 어노테이션이란 어플리케이션이 실행될 때 추가적인 정보를 제공하는 메타 데이터
        - 메타 데이터 → 어플리케이션이 처리해야 할 데이터가 아니라 컴파일 과정과 런타임에서 코드를 어떻게 컴파일하고 처리할 건지에 대한 정보를 담은 데이터
        - 어노테이션은 옵션에 따라 컴파일 전까지만 유효할 수도 있고, 런타임 시기에 처리될 수도 있다.
    - 기본적으로 만들어놓은 커스텀을 import 해서 쓰는게 아니라 내가 필요한 기능을 직접 만들어서 사용하는 어노테이션이 커스텀 어노테이션이다.
    - Custom Annotation의 구성
    
    ```java
        @Target({ElementType.[적용대상]})
        @Retention(RetentionPolicy.[정보유지되는 대상])
        public @interface [어노테이션명]{
            public 타입 elementName() [default 값]
            ...
        }
    ```
    
    - **@Retention** 어노테이션은 어노테이션 정보가 유지되는 범위를 설정한다.
        
        
        | ElementType | 설명 |
        | --- | --- |
        | PACKAGE | 패키지 선언 시 |
        | TYPE | 타입(클래스, 인터페이스, 열거형) 선언 시 |
        | CONSTRUCTOR | 생성자 선언 시 |
        | FIELD | 열거형 상수를 포함 멤버변수 선언 시 |
        | METHOD | 메소드 선언 시 |
        | ANNOTATION_TYPE | 어노테이션 타입 선언 시 |
        | LOCAL_VARIABLE | 파라미터 선언 시 |
        | PARAMETER | 파라미터 선언 시 |
        | TYPE_PARAMETER | 파라미터 타입 선언 시 |
    - **@Target** 어노테이션은 어노테이션을 적용할 수 있는 대상을 설정한다.
        
        
        | RetentionPolicy | 설명 |
        | --- | --- |
        | RUNTIME | 컴파일 이후에도 참조 가능합니다. |
        | CLASS | 클래스를 참조할 때 까지 유효합니다. |
        | SOURCE | 컴파일 이후 어노테이션 정보가 소멸됩니다. |
    - 그럼 이 사용자 어노테이션이랑 AOP를 왜 묶어서 설명 ?
        - AOP는 관심사를 분리하여 코드에 적용하는 프로그래밍 기법
        - **어노테이션**이라는게 이 AOP에서 Advice를 적용할 대상을 지정하는 데 사용되기 때문에 AOP를 잘 사용하려면 어노테이션이 필요하고
        - 결국, **내가 원하는 관심사를 AOP로 빼고 사용자 어노테이션을 붙여서 적용 대상을 지정하는 것이다.**
        
- **📌 ArgumentResolver**
    - Spring MVC 에서는 ArgumentResolver를 사용해서 HTTP 요청의 파라미터를 Controller의 인자로 바로 매핑하는 기능을 제공한다.
    - ArgumentResolver를 정의하려면 `HandlerMethodArgumentResolver` 인터페이스를 implements해서 `supportsParameter` 메서드와 `resolveArgument` 메서드를 오버라이드하면 된다.
        1. supportsParameter
            1. 이 메서드는 이 Argument Resolver가 주어진 매개변수를 해석할 수 있는지 여부를 결정한다. 즉, 어떤 종류의 매개변수에 대해서 이 Resolver를 사용할 것인지를 결정하는 메서드이다.
        2. resolveArgument
            1. 이 메서드는 실제로 매개변수를 해석하는 작업을 수행한다. HTTP 요청을 받아 특정 타입의 객체로 변환하거나, 서비스 레이어로부터 데이터를 가져오는 등의 작업을 수행한다.
        - 예시
            
            ```java
                @RequiredArgsConstructor
                @Component
                public class UserIdResolver implements HandlerMethodArgumentResolver {
                
                    private final JwtService jwtService;
                
                    @Override
                    public boolean supportsParameter(MethodParameter parameter) {
                        return parameter.hasParameterAnnotation(UserId.class) && Long.class.equals(parameter.getParameterType());
                    }
                
                    @Override
                    public Object resolveArgument(@NotNull MethodParameter parameter, ModelAndViewContainer modelAndViewContainer, @NotNull NativeWebRequest webRequest, WebDataBinderFactory binderFactory) {
                        final HttpServletRequest request = (HttpServletRequest) webRequest.getNativeRequest();
                        final String token = request.getHeader("Authorization");
                
                        // 토큰 검증
                        if (!jwtService.verifyToken(token)) {
                            throw new RuntimeException(String.format("USER_ID를 가져오지 못했습니다. (%s - %s)", parameter.getClass(), parameter.getMethod()));
                        }
                
                        // 유저 아이디 반환
                        final String tokenContents = jwtService.getJwtContents(token);
                        try {
                            return Long.parseLong(tokenContents);
                        } catch (NumberFormatException e) {
                            throw new RuntimeException(String.format("USER_ID를 가져오지 못했습니다. (%s - %s)", parameter.getClass(), parameter.getMethod()));
                        }
                    }
                }
            ```
            
    
    이렇게 구현된 ArgumentResolver는 Spring MVC에 등록해서 사용하면 된다.
    
    ```java
        @RequiredArgsConstructor
        @Configuration
        public class WebConfig implements WebMvcConfigurer {
        
            private final UserIdResolver userIdResolver;
        
            @Override
            public void addArgumentResolvers(List<HandlerMethodArgumentResolver> resolvers) {
                resolvers.add(userIdResolver);
            }
        }
    ```
- 👉 `결론`
    - 처음 나는 AOP를 사용하여 ID를 디코딩 하는 로직을 모듈화 하여 사용자 어노테이션으로 만든 다음, 컨트롤러의 파라미터 단에 붙여서 ArgumentResolver를 사용해서 컨트롤러 인자를 바로 매핑해오면 되겠다고 생각했지만, 위의 개념들을 토대로 생각했을 때 이미 @RequestParam 로 받았다는 건 ArgumentResolver를 통해 처리가 된 값이라는 것을 배울 수 있었다.
    - 생각해보면 @PathVariable로 받아올 때 이미 타입 변환을 스프링이 지원해준 것이기 때문에, @PathVariable로 받은 암호화된 String 타입의 특정 ID 값을 복호화된 Long 타입 상태로 변환해주는 컨버터를 구현해서 처리하기로 했다.

## 2025.01.21 (화)
### ✅ TO DO
- 맡은 API 개발
- 여러 API의 path variable로 들어가는 ID 암호화 코드 구현

### 🔥 What I Learned
- 기존에 API를 구현할 떄는 path varible에 pk 값을 그대로 노출하는 것에 대해서 고민해본 적이 없었다. 하지만 우리 서비스의 경우, 링크를 타고 들어오는 경우가 대부분의 케이스이기 때문에 링크를 조작할 수 있다면 보안상 매우 취약할 것이라고 생각했다.
- 이에 pk 자체를 엔드포인트에 노출 했을 때 우려되는 점들에 대해서 고민하고 공부해볼 수 있었다.
    - 인증 및 인가 처리가 우리 백엔드 서비스 내에서는 처리를 다 하고 있지만, 설사 놓친 부분이 있다면 현재 우리의 pk는 auth increment 패턴이기 때문에 pk를 임의로 높이거나 낮춰서 조작하면 안되는 리소스 위치에 접근 할 수 있는 문제점이 있다.
    - 또한 이렇게 되면 공격자는 현재 DB에 저장된 데이터의 개수를 유추하거나, 생성될 리소스의 ID를 예측할 수 있다는 문제도 존재한다.
    - 이를 위해서 적절한 암호화 알고리즘과 비밀키를 사용하여 인코딩 된 ID 값을 엔드포인트에 노출하기로 했다.
    - 자바 환경에서는 javax.crypto 패키지를 통해 AES 대칭키 암호화를 구현할 수 있다. 이를 책임지는 클래스는 IdEncryptionUtil 라는 클래스를 만들어, util 패키지에 넣어두었다.
    - 우리만의 secret key를 16바이트 길의로 정해놓고, 아래와 같이 Long 타입의 pk 값을 AES 알고리즘으로 암호화 한뒤, 이를 Base64 문자열로 인코딩하여 반환한다.
        ```java
            @Value("${encrypt.secret-key}")
            private String secretKey;

            public String encrypt(Long value) throws Exception {
                SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getBytes(), ALGORITHM);
                Cipher cipher = Cipher.getInstance(ALGORITHM);
                cipher.init(Cipher.ENCRYPT_MODE, secretKeySpec);
                byte[] valueBytes = ByteBuffer.allocate(Long.BYTES).putLong(value).array();
                byte[] encryptedData = cipher.doFinal(valueBytes);
                return Base64.getUrlEncoder().withoutPadding().encodeToString(encryptedData);
            }
        ```
    - 이후 디코딩 할 때는 반대로 Chiher 객체를 초기화하고, 암호화할 때 사용한 동일한 비밀 키와 AES 알고리즘을 사용하여 디코딩을 한다.
        ```java
            public Long decrypt(String encryptedData) throws Exception {
                SecretKeySpec secretKeySpec = new SecretKeySpec(secretKey.getBytes(), ALGORITHM);
                Cipher cipher = Cipher.getInstance(ALGORITHM);
                cipher.init(Cipher.DECRYPT_MODE, secretKeySpec);
                byte[] decodedData = Base64.getUrlDecoder().decode(encryptedData);
                byte[] decryptedBytes = cipher.doFinal(decodedData);
                return ByteBuffer.wrap(decryptedBytes).getLong();
            }
        ```

## 2025.01.20 (월)
### ✅ TO DO
- API 개발 전에 공통으로 필요한 클래스 (Exception, Config..) 구현
- 맡은 API 개발 

### 🔥 What I Learned
- 기존에 해왔던 방식대로 GlobalExceptionHandler 클래스 하나 만들고 @RestControllerAdvice를 통해 컨트롤러단에서 발생하는 에러는 한곳에서 처리하도록 구현했다.
- 그래서 service 단에서 우리가 던지는 예외는 모두 잘 잡혀 커스텀되어 내려가는 것을 확인할 수 있었지만, HTTP 메서드를 다르게 (PostMapping한 API에 DELETE로 요청) 하니 해당 요청은 잡지 못하고 500 에러를 뱉는 걸 확인할 수 있었다.
- 해당 문제에 대해 찾아보고 고민한 결과, 명시하지 않은 예외의 경우 Spring MVC Exception이 터지게 되면서 예상한 시나리오대로 GlobalExceptionHandler에서 잡지 못하는 것이었다. -> 물론 잡게 할 수 있지만 그럼 일일히 다 handling 하는 메서드를 추가해주어야 함.
- 해결 방법으로 ResponseEntityExceptionHandler 라는 클래스에서 Spring MVC Exception에 대한 최소한의 처리를 해주고 있기 때문에 이 클래스를 상속 받아서 구현했다.

<br>

## 2025.01.17 (금)
### ✅ TO DO
- AWS IAM 계정 파서 팀원들에게 공유
- AWS 세팅 완료
- dev DB에 더미 데이터 넣기

### 🔥 What I Learned
- IAM 사용자를 생성해서 우리 EC2와 RDS만 접근할 수 있는 최소한의 권한 범위를 주는 것이 목표였는데, 예상치 못한 이슈가 생겼고 이를 해결하면서 정책 문법에 대해서 배울 수 있었다.
    - Effect -> Allow, Resource를 우리 EC2와 RDS로 하고 Effect -> Deny, Resource를 ec2 전체로 세팅하면 우리 꺼만 허용하고 나머지는 접근할 수 없게 세팅이 될 것이라고 예상했지만 우리 리소스에도 계속해서 접근을 할 수 없었다.
    - 공식 문서를 찾아보니 Deny는 항상 Allow보다 우선 되기 때문에 Deny를 다 하고 특정 리소스를 Allow 한다고 해서 되는게 아니었고,Deny를 할려면 Condition 을 줘서 예외를 정의 해줘야 한다 !
    - 그리고 애초에 디폴트로는 Allow 한 거 빼고 나머지는 안되기 때문에 헷갈리지 않게 Allow 만 쓰는게 좋을 것 같다.

<br>

## 2025.01.16 (목)
### ✅ TO DO
- 디자인 회의
- API 명세서 픽스
- AWS 세팅
- Entity 코드 작성성

### 🔥 What I Learned
- AWS 인프라 세팅 할 때, 보안과 과금 방지를 위해서 default VPC가 아닌 choco-letter라는 가상의 네트워크를 만들고 그 위해 public subnet과 private subnet을 구축했다.
- public subnet에는 EC2를 띄우고 private subnet에는 RDS를 띄웠다. 이렇게 하면 우리의 EC2에서만 RDS를 접근할 수 있게 하여서 보안성을 높일 수 있다는 것을 배웠다.
- 이후 데이터그립 등과 같은 IDE에서 접속이 안되어 불편한 문제는 ssh 터널링을 통해 해결했다.
    - ([데이터그립에서 SSH로 연결하는 방법](https://jojoldu.tistory.com/623))
<br>

- 팀원의 Entity 코드 머지 리뷰를 하면서 생성자 패턴에 대해 고민을 좀 해봤다.
    - 다른 프로젝트에서 나는 '파라미터 순서에 대한 휴먼 에러를 줄일 수 있고, 가독성이 좋으며 필요한 값만 세팅할 수 있어서 유연하다'는 장점으로 빌더 패턴을 사용했다.
    - 하지만 무분별하게 빌더패턴을 쓰는건 빌더객체를 추가로 생성해야하는 오버헤드를 가져올 수 있기 때문에 필드 값이 2-3개로 적을 때는 쓰지 않고 그 이상이거나, 아니면 같은 타입의 필드가 많은 경우에만 사용하기로 했다.
    - 또한 정적 팩토리 패턴은 '생성자에 어떤 역할을 메서드명을 통해 분명하게 명시할 수 있다'는 장점이 있어서 사용을 해왔다. 우리 서비스의 경우 선물이 일반 선물과 특별 선물로 나눠지는데 Entity는 Gift로 같기 때문에 이 두 가지 타입의 선물을 생성하는 생성자를 구별할 수 있으면 좋겠다고 생각했다.
    - 근데 또 빌더 패턴을 사용하는 이유가 그럼 퇴색 된다고 생각했기 때문에 빌더패턴을 쓰며 외부에서 직관적으로 확인할 수 있는 방법이 없을까 ? 고민하게 됐다.
    - 찾아보니 하나의 객체에 여러 빌더를 쓸 수 있는데, 빌더 메서드 명도 다르게 세팅이 가능하단 것을 알았다. 그래서 builderMethodName 옵션과 builderClassName 옵션을 줘서 두 개의 빌더 메서드를 생성하는 방식으로 문제를 해결했다.

<br>

## 2025.01.15 (수)
### ✅ TO DO
- API 명세서 작성
- 기획 디벨롭 및 픽스
- 새로운 기능(채팅 시스템)에 대한 러프한 설계
- JIRA 컨벤션 정의 및 백로그 작성

### 🔥 What I Learned
- AWS 인프라 기본 세팅을 하면서 CS 지식이 진짜 중요하다는 것을 깨달았다..
    - ipv4 고갈 현상으로 인해서 ipv6 사용을 권장하는 목적으로 프리 티어 무료 정책이 변경됨에 따라 EC2까지는 괜찮은데 RDS는 퍼블릭 ipv4를 할당하면 과금이라는 것은 이전부터 알고 있었다.
    - 이번 프로젝트부터는 과금 방지의 목적도 있지만, 보안상 누구나 우리 RDS를 접근하게 하는 것이 아니라 EC2의 보안 그룹을 거친 트래픽만 접근할 수 있도록 세팅하는 것이 좋을 것 같았다.
    - 이렇게 세팅 하기 위해서는 VPC와 서브넷 개념을 아는 것이 우선이라고 생각했고, 두 개념을 공부할 수 있는 기회였다. 이 과정에서 네트워크 지식이 단순히 이론적으로만 필요한 것이 아니라는 것을 배울 수 있었다 !
    - 참고 자료 : ([vpc 개념](https://velog.io/@yenicall/AWS-VPC%EC%9D%98-%EA%B0%9C%EB%85%90))
- 채팅 시스템을 구현할 때, 샌드버드와 같은 Saas를 사용할 수 있다는 것을 컨설턴트님과 미팅을 통해 배울 수 있었다. 한번 더 자세히 찾아봐야겠다.

<br>

## 2025.01.14 (화)
### ✅ TO DO
- API 명세서 작성
- ERD 설계
- BE 킥오프 회의
    - 코딩 & 깃 컨벤션 정리
    - 프로젝트 디렉토리 구조 정리
    - BE 내의 일정 대략적으로 정하기
    - 역할 분담
- 컨설턴트님과 코치님들과 미팅
- 미팅 피드백을 기반으로 기획 디벨롭 및 구체화

### 🔥 What I Learned
- 팀 미팅을 통해서 유저 리텐션을 어떻게 하면 더 올릴 수 있을지, 백엔드 개발자 측면에서 이번 프로젝트를 통해 가져갈 수 있는 챌린지 요소가 무엇인지 고민해볼 수 있었다.
- BE 챕터 킥오프 회의를 통해 사용자들에게 각종 카카오톡 알림을 보내주는 부분을 내가 맡게 되었다. 내가 생각했을 때는 단순히 카카오 오픈 API를 통해서 알림을 보내줄 수 있을 것이라고 생각하고 kakao developer 공식 문서에서 관련된 레퍼런스를 찾아보았다.
- 문서를 보며 처음 개념이 헷갈린 부분은 "카카오톡 메세지 보내기" 와 "카카오톡 공유하기" 였다.
- 내가 이해한 바로는 전자는 우리 서비스에서 톡으로 알림을 보내주어야 하는 이벤트가 발생했을 때 카카오톡을 보내주는 것이고, 후자는 우리 서비스에서는 내 선물함 링크를 친구들에게 공유할 때 필요한 기능이라고 생각했다.
- 하지만 데모를 진행해보니 후자에 대한 이해는 맞았지만, 전자는 내가 이해한 것과는 달리 나와 친구들에게 메세지를 보내는 것이었다.
    - 우리가 카카오톡을 보내는 케이스는 특정 유저들에게 공지성 알림을 보내기 위함이기 때문에 적합한 방안이 아니라고 판단했다.
- 이에 다른 API를 찾아봐야 한다는 것을 배울 수 있었던 시간이었다. 
    + 카카오톡 공유하기 API는 REST API는 지원하지 않고 javascript sdk만 지원하기 때문에 위에 말한 두 가지의 API 중 어떤 것을 채택할지 FE측과 논의해봐야겠다고 판단했다.

<br>

## 2025.01.13 (월)

### ✅ TO DO
- 기획 회의
- 회의한 내용을 바탕으로 와이어 프레임 러프하게 짜기
- 기능 명세서 작성

### 🔥 What I Learned
- 서비스를 '개발' 해오던 것과는 다르게, 서비스를 '기획'하는 것은 정말 어렵다는 것을 느꼈다...
- 단순히 어떤 기능을 구상하는 것을 넘어서, 그 기능의 목적을 생각하며 해당 목적을 달성하기 위해 그 기능이 과연 효과적이고 필요한지를 계속 점검하며 기획을 구체화 해나갈 수 있었다.
- 유저의 리텐션을 위한 기능들을 고민해보고, 와이어프레임을 짤 때도 사용자 친화적인 UX를 위해서는 어떤 구조와 뷰 플로우가 좋을지를 고민해보며 하나의 서비스를 제로부터 만들어나가는 것을 배울 수 있었다.

