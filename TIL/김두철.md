# 📝TIL

<br>

## 2025.02.20 (Thu)

### ✅ Today I've done

-   Tanstack Query(구 React Query)의 데이터 캐싱

<br>

### ❣️ Today I've Learned

```
[개요]
TanStack Query는 서버로부터 데이터 가져오기, 데이터 캐싱, 캐시 제어 등 데이터를 쉽고 효율적으로 관리할 수 있는 라이브러리입니다.
React Query라는 이름으로 시작했지만, v4부터 Vue나 Svelte 등의 다른 프레임워크에서도 활용할 수 있도록 기능이 확장되며 TanStack Query라는 이름으로 변경되었습니다.

[대표 기능]
데이터 가져오기 및 캐싱
동일 요청의 중복 제거
신선한 데이터 유지
무한 스크롤, 페이지네이션 등의 성능 최적화
네트워크 재연결, 요청 실패 등의 자동 갱신

[데이터 캐싱]
TanStack Query를 활용해서 데이터를 가져올 때는 항상 쿼리 키(queryKey)를 지정하게 됩니다.
이 쿼리 키는 캐시된 데이터와 비교해 새로운 데이터를 가져올지, 캐시된 데이터를 사용할지 결정하는 기준이 됩니다.
다음 이미지는 쿼리 키와 일치하는 캐시된 데이터가 없을 때, 서버에서 새로운 데이터를 가져오는 과정을 보여줍니다.
서버에서 데이터를 가져오면 그 데이터는 캐시되고 그 이후 요청부터는 캐시된 데이터를 사용할 수 있습니다.
반대로 쿼리 키와 일치하는 캐시된 데이터가 있으면, 서버에 요청하지 않고 캐시된 데이터를 사용하게 됩니다.
따라서 같은 데이터를 가져오는 요청이 여러 번 발생해도, 캐시된 데이터를 사용하게 되어 중복 요청을 줄일 수 있습니다.
그렇다면 한번 캐시된 데이터가 있으면, 서버로는 더 이상 요청을 보낼 수 없는 걸까요?

[핵심 기능]
useQuery
가장 기본적인 쿼리 훅으로, 컴포넌트에서 데이터를 가져올 때 사용합니다.
다음 예제의 지연 응답 API는 t 파라미터 값의 시간이 지난 후 응답합니다.
응답 데이터는 간단한 메시지(message)와 응답 시간(time)을 포함합니다.
```

<br>
<br>

## 2025.02.19 (Wed)

### ✅ Today I've done

-   MySQL InnoDB에서 갭락과 넥스트키 락
-   팬텀 리드 방지

<br>

### ❣️ Today I've Learned

```
[Phantom Read란?]
Phantom Read는 트랜잭션이 동일한 조건의 쿼리를 반복 실행할 때, 나중에 실행된 쿼리에서 처음에는 존재하지 않았던 새로운 행이 나타나는 현상을 말합니다. 이는 주로 읽기 일관성(Read Consistency) 을 유지하는 과정에서 발생할 수 있는 문제로, 데이터의 삽입이나 삭제가 다른 트랜잭션에 의해 이루어질 때 발생합니다.

-- 트랜잭션 A 시작
START TRANSACTION;

-- 트랜잭션 A 첫 번째 조회
SELECT * FROM orders WHERE amount > 150;

-- 트랜잭션 B 시작
START TRANSACTION;

-- 트랜잭션 B 새로운 행 삽입
INSERT INTO orders (customer_id, amount) VALUES (4, 250);

-- 트랜잭션 B 커밋
COMMIT;

-- 동일한 조건으로 트랜잭션 A 두 번째 조회시, 트랜잭션 A의 첫 번째 조회에는 존재하지 않던, 트랜잭션 B에서 삽입된 새로운 행이 함께 조회된다.
-- 단, MVCC를 지원하는 경우 해당 케이스에서 팬텀 리드가 발생하지 않는다.
SELECT * FROM orders WHERE amount > 150;

[갭락(Gap Lock)이란?]
갭 락은 특정 인덱스 값 사이의 공간을 잠그는 락입니다. 기존 레코드 간의 간격을 보호하여 새로운 레코드의 삽입을 방지합니다. 갭 락은 범위 내에 특정 레코드가 존재하지 않을 때 적용됩니다. 트랜잭션이 특정 범위 내에서 데이터의 삽입을 막아 팬텀 읽기(Phantom Read) 현상을 방지합니다. 예를 들어, 인덱스 값 10과 20 사이의 갭을 잠그면 이 범위 내에 새로운 레코드 15를 추가할 수 없습니다.

-- id 1, 3, 5가 저장된 orders 테이블

-- 트랜잭션 A 시작
START TRANSACTION;

-- 트랜잭션 A 1-3과 3-5 사이의 갭과 3 레코드 락 설정(넥스트키 락)
SELECT * FROM orders WHERE orders_id BETWEEN 2 AND 4 FOR UPDATE;

-- 트랜잭션 B 시작
START TRANSACTION;

-- 트랜잭션 B가 id 4에 데이터 삽입 시도 시, 갭락으로 인해 삽입이 차단되어 대기
INSERT INTO orders (orders_id, orders_amount) VALUES (4, 200);
...

[넥스트키 락(Next-Key Lock)이란?]
넥스트키 락은 레코드 락과 갭락을 결합한 형태로, 특정 인덱스 레코드와 그 주변의 갭을 동시에 잠그는 락입니다. 이를 통해 레코드 자체의 변경과 함께 그 주변 공간의 변경도 동시에 제어할 수 있습니다.

넥스트키 락은 특정 레코드와 그 주변 공간을 잠그기 때문에, 다른 트랜잭션이 새로운 레코드를 삽입하여 팬텀 리드를 발생시키는 것을 방지합니다.

-- 트랜잭션 A 시작
START TRANSACTION;

-- 트랜잭션 A amount = 200인 orders_id = 2 레코드에 대한 레코드 락과 1-2, 2-3에 대한 갭락을 동시에 잠금으로써 넥스트키 락을 설정
SELECT * FROM orders WHERE orders_amount = 200 FOR UPDATE;

-- 트랜잭션 B 시작
START TRANSACTION;

-- 트랜잭션 B orders_id = 4, orders_amount = 200인 레코드 삽입 시도 시, 넥스트키 락으로 인해 차단되어 대기
INSERT INTO orders (orders_id, order_amount) VALUES (4, 200);
...

[갭락과 넥스트키 락을 통한 팬텀 리드 방지 매커니즘]
트랜잭션 A가 특정 범위의 데이터를 조회할 때, 해당 범위에 대해 갭락 또는 넥스트키 락을 설정합니다. 락이 설정된 범위 내에서는 트랜잭션 B가 새로운 레코드를 삽입하거나 기존 레코드를 수정하는 것이 차단됩니다. 따라서, 트랜잭션 A가 다시 동일한 조건으로 조회를 수행하더라도, 트랜잭션 B에 의해 새로운 데이터가 삽입되지 않아 팬텀 리드가 발생하지 않습니다.
```

<br>
<br>

## 2025.02.18 (Tue)

### ✅ Today I've done

-   useEffect와 useLayoutEffect의 차이

<br>

### ❣️ Today I've Learned

```
useEffect와 useLayoutEffect는 모두 렌더링된 후에 특정 작업을 수행하기 위해 사용됩니다. 하지만 실행되는 타이밍과 용도가 다릅니다.

먼저, useEffect는 렌더링이 완료되는 시점에 비동기적으로 실행됩니다. 즉, 화면이 실제로 사용자에게 그려진 후에 useEffect가 실행되는 방식입니다. 그래서 useEffect는 보통 데이터를 가져오는 작업이나 이벤트 리스너 추가 등 렌더링 후에 화면에 직접적인 영향을 주지 않는 작업에 주로 사용됩니다.

반면에 useLayoutEffect는 렌더링 후 DOM이 업데이트되기 직전의 시점에 동기적으로 실행됩니다. 여기서 동기적이라는 것은 화면에 내용이 그려지기 전에 모든 레이아웃 관련 작업이 완료된다는 의미입니다. 예를 들어, DOM의 크기를 측정하거나 위치를 조정해야 할 때 useLayoutEffect를 사용하면 즉각적으로 그 변경사항이 반영되어 화면 깜빡임이나 불필요한 재렌더링을 방지할 수 있습니다.

정리하면, 렌더링 후 실행되는 비동기 작업에는 useEffect가 적합하고, 레이아웃 작업이나 DOM 조작과 같이 화면이 그려지기 전에 완료되어야 하는 작업에는 useLayoutEffect가 적합합니다.

예를 들면, useEffect는 사용자 데이터를 API로부터 가져오는 상황에 자주 사용합니다. 데이터가 렌더링 후에 설정되면 화면이 자연스럽게 업데이트되는 것입니다.
```

<br>
<br>

## 2025.02.17 (Mon)

### ✅ Today I've done

-   motion API, ViewTransition

<br>

### ❣️ Today I've Learned

```
[Framer Motion]
Framer Motion은 React로 개발된 애니메이션 라이브러리

[특징]
- TypeScript 지원
- 최적화된 성능 및 풍부한 API
    - physic 기반의 사실적인 트랜지션 효과 제공(spring, tween, inertia)
    - 모던 웹앱에서 반복적으로 필요로 하는 여러 모션들을 간결한 API로 제공
- 선언적인 애니메이션 코드 구현 (with Component Props, React Hook, Util)
- 러닝커브가 동일 카테고리의 타 라이브러리에 비해 낮고 커스텀에 용이함.

[Framer Motion Quick Tutorial]
1. Animation

2. 복잡한 애니메이션 구현을 위한 Variants

3. Layout Animation
4. Gesture Animation
5. Draggable
6. Scroll linked & triggered Animation
7. Motion Values

**번들 최적화를 고려하자!
```

<br>
<br>

## 2025.02.14 (Fri)

### ✅ Today I've done

-   Jest -> 리액트로 테스트 주도 개발(TDD)

<br>

### ❣️ Today I've Learned

```
Jest란?
jest는 페이스북에서 개발한 Javascript 테스트 프레임워크 이고 기본적으로 JS바탕인 프론트엔드 환경에서 많이 쓰인다. 주로 React 애플리케이션과 함께 사용되지만 Babel , TypeScript , Node , Angular , Vue 등을 사용하는 프로젝트에서 작동한다고 Jest 공식 사이트에 나와있다. 이처럼 출시 초기에는 프론트엔드에서 주로 쓰였지만 최근에는 백엔드에서도 기존의 자바스크립트 테스팅 라이브러리를 대체하고 있다. 또한 Jest는 다양한 기능과 쉬운 사용성으로 인기가 높은데 그 예로, config를 따로 설정하지 않아도 빠르게 테스팅 환경을 만들 수 있고, Jest는 라이브러리 하나만 설치하면, Test Runner와 Test Matcher 그리고 Test Mock 프레임워크까지 제공해주기 때문에 따로 다른 라이브러리를 설치하지 않아도 돼서 사용이 편리하다.

React Testing Library란?
React Testing Library는 React 컴포넌트의 테스트를 더 쉽고 직관적으로 작성할 수 있도록 도와주는 라이브러리이다. React Testing Library는 Behavior Driven Test(행위 주도 테스트)를 추구하는 테스트 방법으로 사용자의 관점에서 컴포넌트를 테스트하는 방법을 강조한다. 즉, 컴포넌트의 내부 구현보다는 사용자가 실제로 상호작용하는 방식에 초점을 맞추어 테스트를 작성한다. 그래서 실제 브라우저에서 보여지는 DOM을 기준으로 테스트를 작성하게 된다.

**Jest와 RTL을 같이 사용하는 이유.
두 도구는 React 내에서 테스트를 진행할 때 같이 사용되기에 상호 보완 관계라고 볼 수 있다. (엄밀히 말하자면, RTL이 Jest를 포함하는 구조) 전반적으로 Jest를 통해 기능 테스트를 진행할 수는 있지만, React의 컴포넌트를 렌더링하고 테스트하기 위해서는 몇 가지 기능이 더 필요하다. 그렇기 때문에 React 환경에서는 둘을 같이 사용하는 것이 권장된다.
```

<br>
<br>

## 2025.02.13 (Thu)

### ✅ Today I've done

-   Sentry -> 리액트로 외부 에러 로깅

<br>

### ❣️ Today I've Learned

```
Sentry는 실시간 로그 취합 및 분석 도구이자 모니터링 플랫폼입니다.
로그에 대해 다양한 정보를 제공하고 이벤트별, 타임라인으로 얼마나 많은 이벤트가 발생하는지 알 수 있고 설정에 따라 알림을 받을 수 있습니다.
그리고 로그를 수집하는데서 그치지 않고 발생한 로그들을 시각화 도구로 쉽게 분석할 수 있도록 도와주며 다양한 플랫폼을 지원합니다.

그러면 Sentry의 대표적인 특징에 대해서 간략하게 알아보도록 하겠습니다.

▪ 이벤트 로그에 대한 다양한 정보 제공
Sentry는 발생한 이벤트 로그에 대하여 다양한 정보를 제공합니다.

Exception & Message: 이벤트 로그 메시지 및 코드 라인 정보 (source map 설정을 해야 정확한 코드라인을 파악할 수 있습니다.)
Device: 이벤트 발생 장비 정보 (name, family, model, memory 등)
Browser: 이벤트 발생 브라우저 정보 (name, version 등)
OS: 이벤트 발생 OS 정보 (name, version, build, kernelVersion 등)
Breadcrumbs: 이벤트 발생 과정
Context 기능으로 기본적으로 제공되는 정보 외에 특정 이벤트에 대한 추가 정보를 수집할 수도 있습니다. Context에 대한 내용은 이 아티클의 하단에서 자세히 다룹니다.

▪ 비슷한 오류 통합
Sentry는 Issue Grouping 기능으로 비슷한 이벤트 로그를 하나의 이슈로 통합합니다. 이는 비슷한 오류를 파악하고 추적하는 데 큰 도움이 됩니다.

▪ 다양한 플랫폼 지원
프론트엔드 뿐만 아니라 .NET, Android, Apple(Cocoa), Go, Java, Kotlin, Python 등의 다양한 플랫폼을 지원합니다.

▪ 다양한 알림 채널 지원
발생한 이슈에 대해 실시간으로 알림을 받을 수 있도록 Slack, Teams, Jira, GitHub 등 다양한 채널을 지원합니다.

기본적인 데이터 쌓기
카카오페이에서는 프론트엔드 기술 스택 중 React를 중점적으로 사용하고 있습니다.
```

<br>
<br>

## 2025.02.12 (Wed)

### ✅ Today I've done

-   아이폰 캘린더 기능 구현

<br>

### ❣️ Today I've Learned

```
1. 웹 애플리케이션에서 ICS 파일 생성 및 다운로드

사용자가 웹 페이지에 있는 "일정 다운로드" 버튼을 클릭하면, React/TypeScript 코드가 이벤트 정보(시작/종료 시간, 제목, 설명, 위치, 알림 등)를 기반으로 ICS 파일 형식의 문자열을 생성합니다.
생성된 ICS 파일은 Blob 형태로 만들어지며, 브라우저는 이를 다운로드할 수 있도록 사용자의 로컬 기기로 파일을 저장합니다.

2. ICS 파일 다운로드 완료

사용자는 파일을 다운로드 받아 로컬(예: Downloads 폴더) 또는 모바일 환경에서는 브라우저나 파일 앱에서 파일 목록을 확인할 수 있습니다.

3. ICS 파일 열기

사용자가 다운로드한 ICS 파일을 탭하거나 선택하면, iOS와 같은 모바일 운영체제는 해당 파일 형식을 인식합니다.
iOS는 ICS 파일이 캘린더 이벤트 정보임을 인식하고, 자동으로 캘린더 앱(또는 연관된 앱)을 실행하여 파일 내용을 불러옵니다.

4. 캘린더 앱에서 이벤트 표시 및 사용자 확인

캘린더 앱은 ICS 파일에 담긴 이벤트 세부 사항(예: 제목, 시간, 위치, 알림 설정 등)을 읽어 이벤트 추가 화면을 표시합니다.
이 화면에서는 사용자가 이벤트의 내용을 확인할 수 있으며, “추가” 또는 “저장” 버튼을 통해 캘린더에 이벤트를 등록할지 결정하게 됩니다.

5. 이벤트 추가 및 알림 설정 완료

사용자가 캘린더 앱 내에서 이벤트를 추가하면, 이벤트와 함께 설정된 30분 전 알림(VALARM 정보)도 함께 저장됩니다.
이렇게 추가된 이벤트는 이후 캘린더 앱 내에서 확인 가능하며, 정해진 시간 30분 전에 알림을 표시하게 됩니다.
```

<br>
<br>

## 2025.02.11 (Tue)

### ✅ Today I've done

-   useEffect 의존성 배열 문제

<br>

### ❣️ Today I've Learned

```
리액트에서 useEffect 훅은 컴포넌트의 생명주기와 관련된 부수 효과(side effects)를 관리하는 데 사용됩니다.
useEffect의 두 번째 인자로 전달되는 의존성 배열은 훅이 언제 실행되어야 하는지를 결정하는 역할을 합니다.
의존성 배열에 특정 값을 넣으면, 해당 값이 변경될 때마다 useEffect 내부의 콜백 함수가 재실행됩니다.
배열이 빈 경우, 컴포넌트가 마운트될 때 한 번만 실행됩니다.

문제는 의존성 배열에 무엇을 포함시켜야 하는지 결정할 때 발생합니다.
예를 들어, 콜백 함수 내부에서 외부 변수나 함수에 의존하고 있는데, 이들을 의존성 배열에 포함하지 않으면, 값이 변경되어도 useEffect가 재실행되지 않아 최신 상태를 반영하지 못할 수 있습니다.
반대로, 불필요한 값을 의존성 배열에 넣으면, 원치 않는 재실행이 발생할 수 있습니다.

또한, 의존성 배열에 함수를 넣는 경우가 있는데, 함수가 컴포넌트 내부에서 정의된다면 매 렌더링마다 새롭게 생성되므로 의존성이 계속 변경되어 useEffect가 매번 실행됩니다.
이를 방지하기 위해 useCallback 훅을 사용하여 함수를 메모이제이션 하는 방법이 있습니다.

또 다른 고려 사항은 객체나 배열과 같은 참조형 데이터의 경우입니다.
이들은 내용이 같더라도 매 렌더링마다 새로 생성되면 의존성 배열의 값이 변경된 것으로 인식되어 useEffect가 반복 실행될 수 있습니다.
이러한 경우에도 useMemo나 useCallback을 활용하여 참조를 고정할 수 있습니다.

요약하자면, useEffect의 의존성 배열을 관리할 때는 내부에서 사용되는 모든 외부 값을 고려하여 최신 값을 반영하도록 해야 하며, 불필요한 재실행을 막기 위해 메모이제이션 기법을 사용하는 것이 좋습니다. 이러한 점을 유념하면 useEffect를 더욱 안정적으로 사용할 수 있습니다.
```

<br>
<br>

## 2025.02.10 (Mon)

### ✅ Today I've done

-   API 무한 호출 방지(디바운싱과 쓰로틀링)
-   리액트 쿼리, SWR

<br>

### ❣️ Today I've Learned

```
디바운싱 (Debouncing):
개념: 연속적으로 발생하는 이벤트에 대해 마지막 이벤트가 발생한 후 일정 시간 동안 추가 이벤트가 없을 때 단 한 번 실행하는 기법입니다.
목적: 불필요한 반복 실행을 막아 성능을 최적화하며, 예를 들어 사용자가 입력을 마친 후에만 API 호출을 실행하도록 제어할 수 있습니다.

쓰로틀링 (Throttling):
개념: 이벤트가 짧은 시간 내에 여러 번 발생할 때, 지정한 시간 간격마다 단 한 번만 실행되도록 제한하는 기법입니다.
목적: 과도한 이벤트 호출로 인한 시스템 부하를 줄이고, 예를 들어 스크롤 이벤트를 일정 간격으로 처리하는 데 유용합니다.

리액트 쿼리 (React Query):
개념: React 애플리케이션에서 서버 상태와 API 데이터를 효율적으로 관리할 수 있도록 도와주는 라이브러리입니다.
특징: 자동 캐싱과 deduplication 기능을 제공하여 동일한 쿼리 키를 사용하는 경우 진행 중인 요청을 공유해 중복 호출을 방지합니다. 또한, 백그라운드에서 데이터를 최신 상태로 유지하기 위한 재요청 기능과 에러, 로딩 상태 관리를 간편하게 할 수 있는 도구를 제공합니다.

SWR:
개념: Vercel에서 개발한 데이터 페칭 라이브러리로, "Stale-While-Revalidate" 전략을 사용합니다.
특징: 먼저 캐시된 데이터를 반환한 후, 백그라운드에서 최신 데이터를 가져와 갱신하는 방식으로 동작합니다. 내부적으로 동일 요청에 대한 중복 호출을 방지하며, 간단한 API로 데이터를 손쉽게 페칭할 수 있습니다.

요약하면, 디바운싱과 쓰로틀링은 이벤트 발생 빈도를 제어하는 기법이고, 리액트 쿼리와 SWR은 API 호출 최적화와 데이터 캐싱, 재요청 방지를 위한 라이브러리입니다.
```

<br>
<br>

## 2025.02.07 (Fri)

### ✅ Today I've done

-   구글 애널리틱스

<br>

### ❣️ Today I've Learned

```
구글 애널리틱스 (Google Analytics)란?

구글 애널리틱스는 웹사이트와 앱의 방문자 데이터를 수집하고 분석하여 사용자 행동, 트래픽 소스, 전환 등을 파악할 수 있도록 도와주는 웹 분석 도구입니다.

목적:
웹사이트 및 앱의 성능을 평가하고, 사용자 경험과 마케팅 전략을 개선하기 위한 데이터 기반 의사결정을 지원합니다. 방문자의 행동 패턴을 이해하고, 트래픽 유입 경로와 전환 과정을 분석하여 효과적인 개선점을 도출할 수 있습니다.

특징:
- 실시간 데이터 추적과 보고 기능을 제공하여 현재 방문자 상태를 모니터링할 수 있습니다.
- 방문자 세분화, 사용자 행동 분석, 맞춤 보고서 생성 등 다양한 분석 기능을 지원합니다.
- 구글 애즈, 구글 서치 콘솔 등 다른 구글 서비스와의 연동이 용이하여, 마케팅 캠페인 성과와 SEO 상태를 종합적으로 관리할 수 있습니다.
- 최신 버전인 GA4에서는 이벤트 기반 데이터 모델을 도입해 더 유연하고 정밀한 사용자 행동 분석이 가능하며, 머신러닝을 활용한 예측 분석 기능도 제공합니다.
```

<br>
<br>

## 2025.02.06 (Thu)

### ✅ Today I've done

-   End-to-End 암호화

<br>

### ❣️ Today I've Learned

```
엔드 투 엔드 암호화는 클라이언트 측(예를 들어 리액트 애플리케이션)에서 데이터를 전송하기 전에 암호화하고, 수신자 측에서만 복호화할 수 있도록 하는 보안 방식입니다. 이때 비대칭키 암호화는 공개키와 개인키 쌍을 활용하여, 공개키로 암호화한 데이터는 대응되는 개인키로만 복호화할 수 있도록 보장합니다.

리액트에서 비대칭키를 사용하여 엔드 투 엔드 암호화를 구현하려면 다음과 같은 절차를 따릅니다.

먼저, 수신자의 공개키를 확보해야 합니다. 이 공개키는 암호화에 사용되며, 클라이언트(리액트 앱)는 민감한 데이터를 전송하기 전에 이 키를 이용해 암호화 작업을 수행합니다. 브라우저 내장 API인 Web Crypto API 또는 openpgp.js, jsencrypt와 같은 라이브러리를 활용하면 비대칭 암호화 알고리즘(예를 들어 RSA-OAEP)을 적용할 수 있습니다.

암호화 과정은 비동기적으로 처리되며, 사용자가 입력한 데이터나 전송할 정보를 공개키를 사용해 암호화한 후 암호문 형태로 서버에 전송합니다. 서버는 이 암호문을 중계하거나 저장하지만, 복호화할 수 없으므로 데이터 유출 위험을 줄일 수 있습니다.

수신자 측에서는 사전에 안전하게 보관된 개인키를 사용해 암호문을 복호화하고 원본 데이터를 복원합니다. 이때 개인키는 외부에 노출되지 않도록 엄격히 관리해야 하며, 키 관리 정책이 매우 중요합니다.

핵심 고려사항은 다음과 같습니다.
• 키 관리: 공개키와 개인키의 생성, 안전한 저장, 전송 방법을 신중하게 설계해야 하며, 특히 개인키는 절대 노출되지 않아야 합니다.
• 성능: 브라우저에서 암호화와 복호화 작업이 실행되므로, 처리 시간과 사용자 경험에 미치는 영향을 고려해야 합니다.
• 보안 설정: 사용할 암호화 알고리즘(RSA-OAEP 등)과 그 보안 강도를 적절하게 설정하여, 데이터 보호 수준을 충분히 확보해야 합니다.

요약하자면, 리액트에서 엔드 투 엔드 암호화를 구현할 때는, 수신자 공개키를 이용해 클라이언트 측에서 데이터를 암호화하고, 암호화된 데이터는 서버를 거쳐 전달되더라도 안전하게 보호됩니다. 최종 복호화는 수신자가 자신의 개인키로 수행하며, 이를 위해 Web Crypto API나 관련 암호화 라이브러리를 활용하여 비대칭키 암호화를 적용하게 됩니다.
```

<br>
<br>

## 2025.02.05 (Wed)

### ✅ Today I've done

-   React Router, URL, state

<br>

### ❣️ Today I've Learned

```
리액트 라우터 (React Router) ?
리액트 라우터는 리액트 애플리케이션 내에서 클라이언트 측 라우팅을 구현하는 라이브러리입니다. 페이지 전환이나 URL 변경을 서버에 요청하지 않고, 애플리케이션 내부에서 처리할 수 있게 해줍니다.

목적: 싱글 페이지 애플리케이션(SPA)에서 사용자가 URL 변경을 통해 다양한 뷰로 이동할 수 있도록 하여, 부드러운 내비게이션 경험을 제공하는 것이 목적입니다.
특징:
- 컴포넌트 기반으로 라우트를 정의하며, 각 URL에 해당하는 컴포넌트를 렌더링합니다.
- 동적 라우팅, 중첩 라우트, URL 파라미터 등의 기능을 지원해 복잡한 내비게이션 구조도 쉽게 구현할 수 있습니다.
- 브라우저의 History API를 활용하여 주소 표시줄의 URL을 변경하고, 이를 통해 즐겨찾기나 직접 URL 입력 등 다양한 접근 방식을 지원합니다.

URL ?
URL(Uniform Resource Locator)은 웹 상의 자원을 가리키는 주소로, 브라우저의 주소 표시줄에 나타납니다.

역할: 리액트 라우터에서 URL은 현재 애플리케이션의 위치를 나타내며, 특정 경로에 접근할 때 어떤 컴포넌트를 렌더링할지를 결정하는 기준이 됩니다.
특징:
- 경로(path)와 쿼리 파라미터(query parameter)를 통해 페이지나 상태에 대한 정보를 전달할 수 있습니다.
- 사용자가 직접 URL을 입력하거나 링크를 공유할 수 있도록 해, 애플리케이션의 접근성과 유연성을 높여줍니다.
- URL에 상태 정보를 일부 포함시켜 (예: 검색어, 필터 조건) 사용자 인터페이스의 동적 변화를 유도할 수 있습니다.

state ?
리액트에서 state는 컴포넌트 내부의 데이터나 UI 상태를 저장하고 관리하는 객체입니다.

역할: 컴포넌트가 렌더링하는 내용을 결정하며, state 변경 시 해당 컴포넌트가 다시 렌더링되어 최신 상태를 반영합니다.
특징:
- 로컬 state는 각 컴포넌트 내부에서 관리되며, 사용자 입력이나 이벤트에 따라 동적으로 변경됩니다.
- 리액트 라우터와 함께 사용할 때는, 페이지 이동 시 전달되는 추가 데이터를 관리하는 용도로 활용될 수 있습니다. 예를 들어, Link 컴포넌트나 history API를 사용할 때 state를 함께 전달하면, URL에는 나타나지 않는 임시 데이터를 라우트 간에 공유할 수 있습니다.
- 필요에 따라 전역 상태 관리 라이브러리(Context API, Redux 등)와 연계해 애플리케이션 전체의 상태를 관리할 수 있습니다.
```

<br>
<br>

## 2025.02.04 (Tue)

### ✅ Today I've done

-   CORS, Spring Security

<br>

### ❣️ Today I've Learned

```
📌 CORS ?
Cross Origin Resource Sharing 의 약자
하나의 도메인에서 다른 도메인의 리소스에 접근할 수 있게 해주는 보안 메커니즘
동일 출처 정책(SOP), 즉 프로토콜과 호스트명, 포트가 같은 출처의 리소스에만 접근할 수 있도록 제한하는 정책 때문에 등장했다.
서버 사이드 렌더링으로 자원을 뿌려줄 때는 신경쓸 일이 거의 없지만
요즘에는 API 서버와 클라이언트(리액트나 뷰)를 분리하기 때문에 자주 발생하는 에러이다,,,,

CORS 에러를 해결하기 위해서는 API 서버에서 클라이언트 URL에 대한 리소스 참고를 허용하도록
헤더에 "Access-Control-Allow-Origin" 값을 넣어 응답을 해줘야 한다.
하지만 이 헤더를 보내 해결할 수 없는 경우가 몇 가지 있는데,

GET, POST, HEAD 를 제외한 메소드를 사용
Accept, Accept-Language, Content-Language, Content-Type, DPR, Downlink,
Save-Data, Viewport-Width, Width 를 제외한 헤더를 사용
Content-Type 에서 application/x-www-form-urlencoded, mulitpart/form-data, text/plain 이외의 것을 사용
특히 2번과 3번에서 문제가 되는데 JWT 방식으로 로그인을 구현할 때 X-AUTH-TOKEN 또는 Authorization 헤더를 사용하고
Content-Type 으로 application/json 을 보내는 경우가 많기 때문이다

📌 Preflight
"Access-Control-Allow-Origin" 헤더로 해결할 수 없는 경우 사이트가 안전한지 확인하기 위해 간을 보는데
예비 요청으로 OPTIONS 메서드를 먼저 보내서 판단한 후 본 요청을 보내게 된다
이것이 바로 preflight 요청이다
아까 만났던 에러는 바로 이 preflight 요청을 서버에서 처리하지 못해서
내 요청이 팅겨져 나간 것이다
그러니까 결론적으로는 서버에서 preflight 요청을 처리할 수 있도록
OPTIONS 메서드를 허용해주어야 한다.

```

<br>
<br>

## 2025.02.03 (Mon)

### ✅ Today I've done

-   Mixed Content 오류

<br>

### ❣️ Today I've Learned

```
Mixed content(혼합 콘텐츠)란 ?
최초 HTML이 안전한 HTTPS 연결을 통해 로드될 때 혼합 콘텐츠가 발생하지만 다른 리소스(예: 이미지, 동영상, 스타일시트, 스크립트)는 안전하지 않은 HTTP 연결을 통해 로드 됩니다. 이는 HTTP 콘텐츠와 HTTPS 콘텐츠가 함께 로드되어 동일한 페이지를 표시하므로 혼합 콘텐츠라고 하는데, 최초의 요청은 HTTPS 연결을 통해 보안 처리되었습니다. 최신 브라우저는 이 유형의 콘텐츠에 대한 경고를 표시하여 해당 페이지에 보안되지 않은 리소스가 포함되어 있음을 사용자에게 알려 줍니다.

Mixed Content (혼합 콘텐츠)로 인해 HTTPS의 약화
보안되지 않은 HTTP 프로토콜을 사용하여 하위 리소스를 요청하는 경우 해당 요청은 공격자가 네트워크 연결을 도청하고 양자 간 통신을 보거나 수정하는 수단인 중간자(man-in-the-middle) 공격에 취약하므로 전체 페이지의 보안이 약화됩니다. 공격자는 해당 리소스를 사용하여 손상된 자원뿐만 아니라 페이지를 완전히 제어할 수 있습니다.

대부분의 브라우저가 혼합 콘텐츠 경고를 사용자에게 보고하지만 그때는 너무 늦습니다. 보안되지 않은 요청이 이미 수행되었고 해당 페이지의 보안이 손상되었기 때문입니다. 불행하게도 이 시나리오는 웹에서 흔히 발생하는데, 대부분의 사이트의 기능을 제한하지 않고는 모든 혼합 요청을 차단할 수 없기 때문입니다.
```

<br>
<br>

## 2025.01.31 (Fri)

### ✅ Today I've done

-   로그인, 로그아웃
-   공유코드로 선물상자 구분
-   알림, 캘린더 기능 기획

<br>

### ❣️ Today I've Learned

```
오늘은 프로젝트에서 백엔드 API와의 연동 작업을 진행하면서 로그인, 로그아웃 기능을 구현하고, 공유 코드 기반으로 선물상자를 구분하는 로직을 추가했다.
또한, 향후 개발할 알림 및 캘린더 기능에 대한 기획을 구체화했다.

✅ 1. 로그인 & 로그아웃 기능 구현
사용자 인증을 처리하기 위해 JWT 기반 로그인 및 로그아웃 기능을 구현했다.
소셜 로그인을 하기 위해 백엔드 API로 리다이렉트하고, 성공적으로 인증되면 액세스 토큰을 받아서 로컬 스토리지에 저장하도록 설정했다.
🔹 로컬 스토리지 대신 쿠키를 사용할 수도 있었지만, API 요청 시 토큰을 명시적으로 전달하는 방식이 관리 측면에서 더 명확하다고 판단했다.

🛠 구현 방식
사용자가 아이디/비밀번호 입력 후 로그인 버튼을 클릭하면, API 요청을 보냄
인증 성공 시, 받은 JWT 토큰을 로컬 스토리지에 저장
로그인 후, 메인 페이지로 리다이렉트
로그아웃 시 로컬 스토리지에서 토큰 삭제 후 로그인 페이지로 이동

🔥 추가 개선 사항
자동 로그인 기능: 새로고침해도 유지될 수 있도록 토큰이 유효한지 확인 후 유지하는 기능 추가 예정
API 응답 처리: 실패 시 오류 메시지를 적절하게 사용자에게 표시

✅ 2. 공유 코드로 선물상자 구분
사용자가 특정한 공유 코드를 입력하면, 해당 코드에 연결된 선물상자를 조회할 수 있도록 구현했다.
이 기능을 통해 특정 이벤트 또는 프로모션에서 공유 코드 기반으로 사용자 간 선물 전달이 가능하도록 만들었다.

🛠 구현 방식
사용자가 공유 코드로 통해 본인의 메인 페이지를 구분할 수 있도록 API를 호출하여 공유 코드에 해당하는 선물상자 조회
조회된 선물상자 메인 페이지를 화면에 표시

본인이 로그인 시에 발급받은 공유 코드랑 일치하면 본인 화면,
일치하지 않는다면 그 상대방의 공유 코드로 보여주면 된다. (main/your/before 뷰)
```

<br>
<br>

## 2025.01.28 (Tue)

### ✅ Today I've done

-   로드밸런싱
-   상대방 선물상자 화면 구현

<br>

### ❣️ Today I've Learned

```
개발하는 부분에서 별다른 내용이 발견되지 않아서, 대규모 트래픽 처리와 관련된 내용으로 로드밸런싱에 대해서 공부하게 되었습니다.

1. 로드 밸런싱(Load Balancing)
로드 밸런싱은 네트워크 또는 서버에 가해지는 부하 트래픽을 분산시켜주는 기술

2. 로드 밸런싱의 필요성
웹 비즈니스가 복잡하지 않았던 과거의 웹 서비스는 1대의 서버를 운영하여 클라이언트의 요청을 모두 처리했습니다.
하지만 현대의 웹 서비스 애플리케이션은 사용자의 요구가 점차 늘어나고 비즈니스 복잡도도 크게 증가하여 상당히 무거운 웹 애플리케이셔으로 변화되었고
이에 따라 클라이언트의 수도 기하급수적으로 늘어나게 되어 기존보다 서버의 부하가 크게 증가하였습니다.

이에 따라 서버의 부하를 줄일 기술이 필요해졌고, 로드 밸런싱은 여러 대의 서버를 두고 서비스를 제공하는 분산 처리 시스템에서 반드시 필요한 기술입니다.

3. 서버를 확장하는 방법 : Scale up, Scale out
- Scale up : 서버의 사양 자체를 높이는 것
- Scale out : 서버의 개수를 늘리는 것
```

<br>
<br>

## 2025.01.27 (Mon)

### ✅ Today I've done

-   EDA와 Apache Kafka
-   디자인 변경에 따른 코드 수정

<br>

### ❣️ Today I've Learned

```
오늘은 지금까지 만들어두었던 부분에 대하여 디자인 변경점을 전부 반영하였고, 이후부터는 다시 새로운 작업에 대해서 진행할 예정이다.
그리고 이벤트 중심 아키텍처와 카프카에 대해서 공부했다.

데이터 스트리밍의 중요성
데이터 스트리밍은 데이터가 생성되는 즉시 지속적으로 데이터를 수집, 처리, 분석하는 기술을 말합니다.
해당 방법은 전통적인 배치 처리 방식과 대비되며, 실시간으로 정보를 파악하고 즉각적인 피드백 루프를 생성할 수 있다는 점이 가장 큰 장점입니다. 아래는 스트리밍 데이터 처리가 쓰이고 있는 예시입니다.

예를 들어, 금융 서비스 업계에서는 주식 시장의 변동을 실시간으로 감지하고 자동으로 거래를 실행하는 알고리즘 거래 시스템이 필요합니다. 또한, 전자상거래 플랫폼은 사용자의 클릭스트림 데이터를 실시간으로 분석하여 개인화된 상품 추천을 제공해야 합니다.

이처럼 최신에 들어서는, 웬만한 기업은 서비스의 원활한 운영과 실시간 데이터 분석을 위해 스트리밍 데이터를 처리하려고 노력하고, Kafka나 Flink와 같은 프레임워크를 하나 이상 채용하여 사용하고 있습니다.

가장 먼저 스트리밍 데이터 플랫폼을 알아보기 위해 필요한 개념은 이벤트 기반 아키텍처 (Event-Driven-Architecture) 입니다.

이벤트 기반 아키텍처 (Event-Driven-Architecture)
비즈니스는 수도 없이 많은 동적인 사건들의 발생으로 이루어져 있습니다. 유저의 회원가입부터 로그인, 장바구니 담기, 상품 구매, 상품 재구매 까지 모두 이벤트의 일종이라고 볼 수 있습니다.

이벤트 기반 워크플로우에서는 데이터 엔지니어링 수명 주기의 다양한 부분에서 이벤트를 생성, 라우팅, 소비의 프로세스가 진행됩니다.
이벤트 기반 아키텍처에서는 위에서 설명한 워크플로우를 기반으로 다양한 서비스간 통신을 진행합니다.

해당 아키텍처의 장점은 이벤트의 상태를 여러 서비스에 분산시키기 때문에, 오프라인 상태가 되거나, 분산 시스템에서 노드에 장애가 발생하거나, 여러 소비자 또는 서비스가 동일한 이벤트에 접근하도록 할 때 유용하다는 점입니다. 보통, 서비스가 느슨하게 결합된 경우에는 항상 이벤트 중심 아키텍처를 포함합니다.

이벤트 기반 아키텍처는 아래와 같은 이유로 인기가 더욱 높아지고 있습니다.

이벤트 기반 아키텍처의 핵심 계층인 메시지 큐와 이벤트 스트리밍 플랫폼은 클라우드 환경에서 더 쉽게 설정하고 관리 가능
실시간 분석을 직접 통합하는 어플리케이션인 데이터 앱의 증가
핵심적으로, 이벤트 기반 아키텍처는 이벤트가 어플리케이션 작업을 트리거하고 실시간에 가까운 분석을 제공할 수 있습니다.

또한, 데이터 수집과 변환 단계에서도 원천 시스템에서 메시지 전달을 위해 사용했던 것과 같은 이벤트 스트리밍 플랫폼을 사용하여 실시간 분석을 위한 데이터를 처리할 수 있다는 점이 주요합니다.

보통 파이프라인의 성능은 두 가지로 결정됩니다. 바로 latency와 처리량 입니다.
아무래도 스트리밍 데이터를 처리하는 프레임워크는 그 성격 상 latency에 치중될 수 밖에 없습니다.
그러나, Kafka는 디스크 기반의 로깅 메커니즘을 통해 처리량 또한 준수한 수준을 보입니다.

특히, Kafka 는 강력한 데이터 복제를 브로커를 통해 지원합니다.

브로커는 Kafka 클러스터를 구성하는 기본 단위입니다. Kafka 에서는 데이터를 여러 브로커에 복제하여 저장하여, 어떤 브로커에 문제가 발생해도 데이터 손실 없이 처리를 계속할 수 있음을 의미하며, 실시간 시스템에서는 이러한 내구성이 매우 중요한 요소로 작용합니다.

추가로, 분산 시스템으로 설계되어 있어 데이터를 여러 서버(브로커)에 걸쳐 저장하고 처리할 수 있기에, 단일 노드의 성능 한계를 넘어서는 확장성과 높은 처리량을 가능하게 합니다.

이외에도, Kafka는 다양한 프로그래밍 언어 및 프레임워크와의 호환성, 그리고 이미 형성되어 있는 대규모 커뮤니티 지원을 통해 많은 기업들이 Kafka를 채용하여 비즈니스 데이터를 효율적으로 관리하고 있습니다.

Kafka Architecture
Kafka config: Topic, Partition, Replica, Leader, Follower…. etc

토픽과 파티션은 위에서 이미 언급했지만, 조금 더 상세한 이해를 위해 구체적으로 한번 더 짚고 넘어가겠다.

토픽 (Topic)
토픽은 데이터의 카테고리나 분류를 나타내는 단위입니다.
예를 들어, "user_signups" 또는 "order_transactions"와 같은 토픽을 만들 수 있습니다. 각 토픽은 하나 이상의 파티션을 가질 수 있습니다.

파티션 (Partition)
파티션은 토픽의 데이터를 분할하는 단위입니다.
토픽의 데이터가 여러 파티션에 나누어 저장되어 사용되기 때문에, 병렬 처리를 통해 높은 처리량을 달성할 수 있습니다. 처음, 해당 개념을 접했을 때 혼자 아래와 같은 예시를 만들어 이해하려고 애썼던 기억이 있다.

예를 들어, "user_signups"라는 토픽이 3개의 파티션으로 구성되어 있다면:

파티션 1: 사용자 가입 데이터의 1/3
파티션 2: 사용자 가입 데이터의 1/3
파티션 3: 사용자 가입 데이터의 1/3
이렇게 각 파티션은 토픽의 전체 데이터 중 일부를 독립적으로 저장합니다.

프로듀서가 토픽에 메시지를 쓸 때, Kafka는 해당 메시지를 특정 파티션에 할당합니다. 이 할당은 여러 가지 방법(예: 라운드 로빈, 키 해싱 등)으로 수행될 수 있습니다. 따라서, 기본적으로 토픽의 모든 데이터를 조회하려면 모든 파티션에서 데이터를 읽어와야 합니다.
단, 각 파티션 내에서의 메시지 순서는 유지되지만, 토픽 전체의 파티션 간 메시지 순서는 보장되지 않을 수 있습니다.

복제본 (Replica)
복제본은 파티션의 복사본으로, 데이터의 내구성과 고가용성을 보장하기 위해 사용됩니다.

위에서 언급했다시피, 만약 한 브로커가 실패하더라도 해당 브로커에 저장된 파티션의 복제본이 다른 브로커에 존재하기 때문에 데이터 손실을 방지할 수 있습니다.

Segment
Segment는 브로커의 로컬 스토리지에 저장되는 파티션의 물리적인 저장 단위입니다.

파일 기반 저장: 각 세그먼트는 실제로 두 가지 주요 파일로 구성됩니다. 하나는 실제 메시지를 저장하는 .log 파일, 그리고 메시지의 위치를 빠르게 찾기 위한 .index 파일입니다.
Rolling: 세그먼트는 설정된 크기나 기간에 도달하면 "roll" 되며, 새로운 세그먼트 파일이 생성됩니다. 이것은 오래된 데이터를 효율적으로 삭제하거나 관리할 수 있게 해주는 장점이 있습니다.
데이터 삭제 및 보존: 오래된 데이터를 삭제할 때, Kafka는 전체 세그먼트 파일을 삭제함으로써 효율성을 유지합니다. 데이터 보존 정책(retention policy)에 따라, 메시지가 보존되는 시간이나 세그먼트의 크기에 도달하면 해당 세그먼트는 삭제될 수 있습니다.
효율적인 읽기 및 쓰기: 세그먼트 구조는 Kafka가 대량의 데이터를 빠르게 읽고 쓰는 데 있어 효율적입니다. 특히, 순차적인 디스크 I/O 작업은 랜덤 액세스보다 훨씬 빠르기 때문에 세그먼트는 이러한 순차적인 접근의 이점을 활용합니다.
각 파티션은 리더(leader)와 하나 이상의 팔로워(follower)로 구성

쓰기 작업: 프로듀서가 데이터를 쓰려고 할 때, 이 작업은 해당 파티션의 리더에게 전달됩니다. 오직 리더만이 해당 파티션에 데이터를 쓸 수 있습니다.
팔로워 동기화: 리더가 데이터를 받고 기록한 후, 이 데이터는 팔로워들에게 복제됩니다. 팔로워는 리더로부터 데이터를 주기적으로 가져와서 자신의 로그에 동기화합니다. 이렇게 해서, 만약 리더가 실패하면, 팔로워 중 하나가 새로운 리더로 승격될 수 있으며, 데이터 손실 없이 서비스를 계속 제공할 수 있습니다.
읽기 작업: 컨슈머가 데이터를 읽을 때 기본적으로 리더에서 데이터를 읽습니다. 그러나 Kafka 설정에 따라, 컨슈머가 팔로워 브로커로부터 직접 데이터를 읽는 것도 가능하며, 이를 통해 읽기 처리량을 분산시킬 수 있습니다.
```

<br>
<br>

## 2025.01.26 (Sat)

### ✅ Today I've done

-   Kubernetes와 Container Orchestration
-   디자인 변경에 따른 코드 수정

<br>

### ❣️ Today I've Learned

```
오늘도 디자인 변경에 따른 코드 수정 이후에, 대규모 서비스를 대비하여 쿠버네티스에 대해서 공부해보았다.

쿠버네티스(Kubernetes)란?
쿠버네티스(Kubernetes)는 컨테이너화 된 애플리케이션의 대규모 배포, 스케일링 및 관리를 간편하게 만들어주는 오픈 소스 기반 컨테이너 오케스트레이션(Container Orchestration) 도구다.

같은 역할을 하는 도구로서 도커 스웜(Docker Swarm), 아파치 메소스(Apache Mesos), 노마드(Nomad) 등이 대규모 컨테이너의 효율적 제어라는 동일한 목적 아래 발전되어 왔으나, 2022년 현재는 쿠버네티스가 컨테이너 기반 인프라 시장에서 사실상의 표준으로 자리 잡은 상태다.

쿠버네티스는 과거 15년이 넘는 시간 동안 구글 내부에서 프로덕션 규모의 워크로드를 운영하는 수단으로 사용되었던 역사를 지녔다. 이렇게 검증받은 신뢰성과 효용이 쿠버네티스를 시장 지배적인 위치로 끌어올렸다. 이미 글로벌 3대 클라우드사(AWS, Azure, GCP) 뿐만 아니라 RedHat, VMWare 등에서도 자사 솔루션에 최적화된 버전의 쿠버네티스 플랫폼을 제공하고 있다. 공공/민간 IT 인프라의 클라우드 전환이 빠르게 일어나는 가운데, 앞으로의 애플리케이션 운영 인프라를 다루는 과정에서 쿠버네티스에 대한 이해는 필수가 될 것이다.

쿠버네티스의 쓸모와 목적을 이해하려면 컨테이너 오케스트레이션(Container Orchestration)을 함께 알아야 한다. 우선 컨테이너 오케스트레이션(Container Orchestration)의 개념과 필요성이 발생하게 된 배경을 간단히 소개하고, 다음으로는 이것의 구현체로서 쿠버네티스가 가진 핵심적인 설계 사상들을 살펴보기로 한다.

컨테이너 오케스트레이션(Container Orchestration)란?
레드햇(Red Hat)의 정의에 따르면, IT 업계에서 오케스트레이션(Orchestration)이란 용어는 "컴퓨터 자원과 어플리케이션, 서비스에 대한 자동화된 설정, 관리 및 제어 체계"를 의미한다. 같은 의미를 차용하여 컨테이너 오케스트레이션(Container Orchestration)을 해석하자면, "컨테이너화 된 애플리케이션에 대한 자동화된 설정, 관리 및 제어 체계"로 받아들일 수 있을 것이다.

마이크로서비스 아키텍처(MSA; Microservice Architecture)에서는 프로젝트에 포함된 세부 기능들이 작은 서비스 단위로 분리되어 구축된다. 이 각각의 서비스를 구현할 때 컨테이너 기술이 흔하게 이용된다. 한정된 적은 양의 컨테이너는 개별 관리자가 손수 관리할 수도 있겠지만, 대규모의 상용 프로젝트 환경에서 수많은 컨테이너를 이런 식으로 제어하는 것은 불가능하다. 동시에 수백, 수천 개의 컨테이너를 배포하고 관리해야 하는 상황이라면 아래의 4가지 이슈에 대한 해답을 반드시 찾아야 한다.

배포 관리 : 어떤 컨테이너를 어느 호스트에 배치하여 구동시킬 것인가? 각 호스트가 가진 한정된 리소스에 맞춰 어떻게 최적의 스케줄링을 구현할 것인가? 어떻게 하면 이러한 배포 상태를 최소한의 노력으로 유지 관리할 수 있을 것인가?
제어 및 모니터링 : 구동 중인 각 컨테이너들의 상태를 어떻게 추적하고 관리할 것인가?
스케일링 : 수시로 변화하는 운영 상황과 사용량 규모에 어떻게 대응할 것인가?
네트워킹 : 이렇게 운영되는 인스턴스 및 컨테이너들을 어떻게 상호 연결할 것인가?
각기 다른 요소들을 동시에 안정적으로 제어하는 것이 오케스트레이션의 핵심 역할이다.
각기 다른 요소들을 동시에 안정적으로 제어하는 것이 오케스트레이션의 핵심 역할이다.
위의 4가지 이슈를 해결하기 위해 나타난 개념이 바로 컨테이너 오케스트레이션(Container Orchestration)이다. 관현악 연주에서 각기 다른 파트를 맡은 연주자들이 하나의 연주를 위해 동시에 조화를 이루듯이, 온라인 인프라 환경에서 대규모의 컨테이너들이 안정적으로 운영될 수 있도록 관리의 복잡성을 줄여주고 이를 자동화하는 것이다. 쿠버네티스는 이러한 컨테이너 오케스트레이션 개념을 구현한 도구들 중 하나다.

쿠버네티스의 핵심 설계 사상 5가지
1. 선언적 구성 기반의 배포 환경
2. 기능 단위의 분산
3. 클러스터 단위 중앙 제어
4. 동적 그룹화
5. API 기반 상호 작용
```

<br>
<br>

## 2025.01.25 (Sat)

### ✅ Today I've done

-   MongoDB, Redis
-   디자인 변경에 따른 코드 수정

<br>

### ❣️ Today I've Learned

```
오늘은 디자인 변경에 따른 코드 수정 이후에 가볍게 DB에 대해서 공부했다.

🔍 데이터 구조 및 저장 형식
Redis는 Key-Value 형태의 데이터 구조를 가지는 인메모리 데이터 저장소입니다. 반면, MongoDB는 Document 형태의 데이터 구조를 가지며, 디스크 기반으로 데이터를 저장합니다. 이러한 차이로 인해 Redis는 메모리 기반으로 빠른 데이터 처리가 가능하며, 주로 캐싱에 사용되는 반면, MongoDB는 대용량의 데이터를 저장하고 관리하는 데 적합합니다.

✅ 확장성
Redis와 MongoDB 모두 수평적 확장을 지원하며, 샤딩을 통해 데이터를 여러 서버로 분산시킬 수 있습니다. 하지만 MongoDB는 복제 세트를 이용하여 데이터의 고가용성을 보장하고, 자동 복구 기능을 제공합니다.

✅ 지원 쿼리
Redis는 기본적인 Key-Value 연산뿐만 아니라, 데이터 구조별로 복잡한 연산을 지원합니다. 반면, MongoDB는 다양한 쿼리 연산을 제공하며, 인덱싱 및 집계 파이프라인 등의 고급 기능을 사용할 수 있습니다.

✅ 데이터 유지 및 성능
Redis는 주로 캐싱에 사용되기 때문에, 메모리 기반으로 고속의 데이터 처리가 가능합니다. 영속성이 필요한 경우, RDB (Redis Database) 및 AOF (Append-Only File) 옵션을 제공하여 메모리에 있는 데이터를 디스크에 저장할 수 있습니다. 하지만, 이러한 옵션은 추가적인 설정과 관리가 필요합니다. 반면, MongoDB는 메모리 매핑을 이용하여 빠른 데이터 처리가 가능하며, 기본적으로 데이터를 디스크에 저장하여 데이터 영속화를 지원합니다.

📝 사용 사례 및 대표적인 사용 기업 차이
Redis는 캐싱, 메시징, 실시간 분석, 게임 랭킹, 세션 관리 등 다양한 분야에서 사용됩니다. 대표적으로 Twitter, GitHub, StackOverflow, Pinterest 등의 기업에서 사용되고 있습니다. 반면, MongoDB는 웹 애플리케이션, 모바일 애플리케이션, 로그 관리, IoT 등의 분야에서 활용되며, Adobe, eBay, Expedia, Cisco 등의 기업에서 사용되고 있습니다.
```

<br>
<br>

## 2025.01.24 (Fri)

### ✅ Today I've done

-   프론트엔드 전체 코드 리뷰
-   메인 화면 대대적 개편
-   튜토리얼 아이콘 강조 오버레이 구현
-   마이 페이지 드롭다운 구현

<br>

### ❣️ Today I've Learned

```
오늘은 프론트엔드 팀원들과 함께 전체 코드 리뷰를 진행하였습니다.
Align을 맞출 목적도 있었지만 다같이 어떤 코드를 쓰는 게 좋은 건지 얘기하는 시간을 많이 가졌습니다.

1. React 18의 주요 변경 사항

[Concurrent Rendering]
이전 버전보다 더욱 개선된 병렬 렌더링 방식을 지원하여, UI 업데이트의 우선순위를 효율적으로 처리할 수 있게 됐습니다.
예를 들어, startTransition과 useTransition 같은 API를 활용해 비동기적인 상태 업데이트 로직을 구성할 수 있습니다.

[자동 배칭(Automatic Batching) 확장]
기존에는 이벤트 핸들러 내에서만 배칭이 일어났지만, React 18부터는 setTimeout, fetch 등
이벤트 핸들러가 아닌 곳에서 일어난 상태 업데이트에도 자동으로 배칭이 적용됩니다.

[Suspense 기능 강화]
데이터 패칭과 Suspense를 결합해 로딩 상태를 보다 직관적으로 표현할 수 있게 됐습니다.
서버 사이드 렌더링(SSR)에서도 스트리밍 렌더링과 결합해 다양한 렌더링 전략을 취할 수 있습니다.

2. 타입스크립트와 React 컴포넌트

[React.FC]
팀 내에서 React.FC를 사용할지 말지에 대해 이야기를 나눴는데,
React.FC 사용 시에는 children이 자동으로 타입에 포함되어 편리하지만,
defaultProps, displayName 같은 속성 활용은 최근 공식 문서에서 권장되지 않기도 하고,
기본 함수 컴포넌트 시그니처(function ComponentName(props: Props) {})와 큰 차이는 없습니다.
각 팀원별로 스타일을 어느 정도 통일하자는 결론에 도달했습니다.

[Props 타입 정의]
Props에 타입을 선언할 때, type 혹은 interface를 어떻게 사용하면 좋을지 이야기를 나눴습니다.
interface는 확장이 수월하고, type은 좀 더 유연하게 여러 타입 조합이나 유니온을 합치기 쉽습니다.
팀에서는 크게 제한하지 않고 적절한 경우를 구분해 쓰기로 했습니다.

[함수형 컴포넌트의 반환 타입]
함수형 컴포넌트는 JSX.Element 혹은 ReactElement 타입을 반환하는 것이 일반적입니다.
TS에서 별도의 반환 타입을 명시하기보다는, TS가 추론하도록 두는 방향이 확장성과 가독성 면에서 좋다는 의견이 많았습니다.

3. JavaScript 함수 사용에 대한 논의

[화살표 함수 vs 전통적 함수 선언]
팀 내에서 컴포넌트를 선언할 때 화살표 함수 표현식을 선호하는지, function 키워드를 선호하는지 의견이 다양했습니다.
최종적으로는 아래 기준으로 통일했습니다.
컴포넌트 선언 시에는 화살표 함수(const Component: React.FC<Props> = (props) => { ... })를 쓰되,
클래스 혹은 라이브러리 등의 유틸 함수에서는 전통적 함수 선언(function funcName(...) {})을 자유롭게 사용.

[함수 디폴트 파라미터와 옵셔널 파라미터]
함수 시그니처를 정의할 때, 디폴트 파라미터((param = 'default') => ...) 대신
옵션 파라미터((param?: string) => ...)를 언제 쓰는 게 좋은지 예시를 가지고 토론했습니다.
디폴트 값을 넣으면 호출하는 쪽에서 직관적일 수 있지만, 옵셔널 파라미터는 추가적인 분기 처리를 구현하는 데 유연합니다.
상황에 따라 다르지만, 명확한 기본값이 필요한 경우엔 디폴트 파라미터를 적극적으로 사용하기로 했습니다.

4. 기타 정리 사항

[에러 바운더리(Error Boundary)]
React 18에서 별다른 변화가 있는 건 아니지만, 에러 바운더리를 적절히 구현해 예상치 못한 에러가 발생해도 전체 앱이 죽지 않도록 해야 한다는 이야기를 나눴습니다.

[코드 스플리팅(Code Splitting)]
Suspense와 동적 임포트를 같이 쓰면, 페이지 단위 혹은 컴포넌트 단위로 코드를 스플릿할 수 있어 초기 로딩 속도를 개선할 수 있다고 재확인했습니다.

[다양한 상태 관리 라이브러리]
Redux, Zustand, Recoil 등 상태 관리 라이브러리를 어떻게 TypeScript와 결합하면 편하게 쓸 수 있는지 짧게 언급했습니다.
프로젝트 특성 상 우선 Recoil 기본으로 사용해보고 있습니다.
```

<br>
<br>

## 2025.01.23 (Thu)

### ✅ Today I've done

-   React API 설정
-   React 테스트 페이지 작성(Jest 포함)
-   캡처 버튼 구현
-   전체 화면 레이아웃 다시
-   Figma 디자인 특강

<br>

### ❣️ Today I've Learned

```
오늘은 View에 집중하기보다 기능이나 프로젝트 구조설계 부분을 신경썼습니다.

1. API 설정
프로젝트의 효율적인 API 통신을 위해 Axios를 활용한 공통 API 설정을 도입했습니다.
이를 통해 API 호출 시 반복되는 설정을 줄이고, 코드의 재사용성을 높일 수 있었습니다.
특히, 인증이 필요한 요청에 대해서는 Authorization Bearer 토큰을 자동으로 포함하도록 설정하여 보안성을 강화했습니다.
공통 컴포넌트로 분리함으로써 모든 API 요청이 일관된 방식으로 처리되도록 관리할 수 있게 되었고, 이는 유지보수와 확장성 측면에서도 큰 도움이 되었습니다.

2. 테스트 페이지 및 Jest
프로젝트의 안정성과 신뢰성을 높이기 위해 Jest를 활용한 테스트 환경을 구축했습니다.
테스트 주도 개발(TDD)을 추후에 적용하여 기능 구현 전에 테스트를 먼저 작성함으로써 코드의 정확성을 검증하고,
예상치 못한 버그를 사전에 방지할 수 있을 것 같습니다. 특히, 컴포넌트 단위 테스트를 통해
각 컴포넌트가 의도한 대로 동작하는지를 확인할 수 있을 것 같고 API 호출에 대한 테스트를 통해
데이터 흐름의 일관성을 유지할 수 있었습니다. 이러한 테스트 과정은 프로젝트의 유지보수성과 확장성을 크게 향상시켰습니다.

3. 캡처 버튼 구현
사용자가 웹 애플리케이션 내에서 모바일 디바이스의 화면을 손쉽게 캡처할 수 있도록 캡처 버튼을 구현했습니다.
이를 통해 사용자는 특정 요소의 화면을 이미지 파일로 저장하거나 공유할 수 있게 되었으며,
이는 사용자 경험을 크게 향상시키는 기능입니다. 특히, 웹 환경에서 모바일 디바이스의 화면을
정확하게 캡처하기 위해 관련 라이브러리를 활용하여 구현함으로써, 다양한 디바이스에서도 일관된 캡처 기능을 제공할 수 있게 되었습니다.
이러한 기능은 디버깅이나 사용자 피드백 수집 시에도 유용하게 사용될 수 있습니다.
```

<br>
<br>

## 2025.01.22 (Wed)

### ✅ Today I've done

-   Concurrent Mode (React 18)
-   React QRCode 그리기
-   카카오톡 공유 API (JavaScript)
-   메인 화면 - 공유 기능 개발
-   Figma 디자인 특강

<br>

### ❣️ Today I've Learned

```
오늘은 메인 화면의 공유 기능을 개발하면서 여러 가지 중요한 개념과 기술을 배웠다. 특히 Concurrent Mode에 대한 이해가 가장 큰 수확이었다. 오늘 학습한 내용은 다음과 같다.

1. React QRCode 그리기

React를 활용하여 QR 코드를 생성하고 화면에 표시하는 방법을 학습했다. qrcode.react와 같은 라이브러리를 사용하여 간단하게 QR 코드를 렌더링할 수 있었고, 사용자에게 필요한 정보를 시각적으로 제공하는 데 유용하게 적용할 수 있었다.

2. 카카오톡 공유 API (JavaScript)

카카오톡의 공유 API를 JavaScript로 통합하는 방법을 배웠다. 카카오 개발자 문서를 참고하여 API 키를 설정하고, 사용자들이 버튼 클릭 시 간편하게 콘텐츠를 카카오톡으로 공유할 수 있도록 구현했다. 이를 통해 사용자 경험을 크게 향상시킬 수 있었다.

3. Concurrent Mode (React 18)

React 18에서 도입된 Concurrent Mode에 대해 깊이 있게 공부했다. Concurrent Mode를 사용하면 애플리케이션의 반응성을 높이고, 복잡한 UI 업데이트도 부드럽게 처리할 수 있다는 점을 깨달았다. 실제로 메인 화면 공유 기능을 개발하면서 Concurrent Mode의 장점을 실감할 수 있었고, 향후 프로젝트에서도 적극적으로 활용할 계획이다.

오늘 배운 내용을 바탕으로 앞으로 더 효율적이고 사용자 친화적인 기능을 개발할 수 있을 것 같아 뿌듯하다. 내일도 새로운 기술들을 계속해서 습득하고 싶다!
```

<br>
<br>

## 2025.01.21 (Tue)

### ✅ Today I've done

-   React에서 컴포넌트 마운트/언마운트 시 이벤트 리스너 관리
-   온보딩 뷰
-   공유 기능 모달
-   Figma 디자인 특강

<br>

### ❣️ Today I've Learned

```
오늘은 개발 위주로 진행하였고, 저녁엔 특강이 있어 간단하게 공부한 자료를 정리했습니다.
React에서 컴포넌트 생애주기에 따라서 이벤트 리스너 관리하는 부분에 대해서 컨설턴트님께서 말씀을 주셨습니다.

그래서 정확히 왜 필요할까? 부터 짚어 넘어갈 수 있는 시간을 가져보기로 결심했습니다.

우선, 결론부터 확인하면 메모리 누수 방지 및 성능 최적화를 위해 중요한 것으로 파악했습니다.

1. 메모리 누수 방지
- 컴포넌트가 언마운트되었는데도 이벤트 리스너가 남아 있으면, 리스너가 계속 메모리를 점유하게 된다.
이는 애플리케이션이 점점 더 많은 메모리를 사용하게 되어 성능 저하를 초래함.

2. 불필요한 함수 호출 방지
- 리스너가 제거되지 않으면, 이벤트가 발생할 때 언마운트된 컴포넌트의 핸들러 함수가 호출됨.
이는 의도하지 않은 동작이나 오류를 발생시킬 수 있음.

3. 성능 최적화
- 컴포넌트마다 독립적으로 이벤트 리스너를 추가하고 제거하면 필요한 리소스를 최소화하여
애플리케이션의 성능을 유지할 수 있음.

!!! 이벤트 리스너를 제거하기 위해서는 React의 useEffect 훅에서 클린업 함수를 반환하여 수행하면 됨!

예제 코드는 아래와 같다.
  useEffect(() => {
    // 마운트 시 이벤트 리스너 추가
    window.addEventListener('scroll', handleScroll);

    // 언마운트 시 이벤트 리스너 제거
    return () => {
      window.removeEventListener('scroll', handleScroll);
    };
  }, []); // 빈 배열로 의존성을 설정하여 마운트/언마운트 시에만 실행


이제는 백엔드를 넘어서 프론트에서도 더욱 메모리 및 성능을 고려할 수 있는 개발자가 되어보도록 하자!
```

<br>
<br>

## 2025.01.20 (Mon)

### ✅ Today I've done

-   전역 상태 관리 & 상태 관리 라이브러리
-   로그인, 온보딩 뷰 개발
-   React 18 프로젝트 생성 및 설정(CSR, SSR, SSG 비교 / SEO를 위한 선택)
-   SWC와 Bable : 컴파일러에 대하여

<br>

### ❣️ Today I've Learned

```
상태란 무엇일까? 리액트 애플리케이션에서의 상태는 렌더링에 영향을 줄 수 있는 동적인 데이터 값을 말한다.
- 렌더링 결과에 영향을 주는 정보를 담은 순수 자바스크립트 객체

리액트에서의 상태는 시간이 지나면서 변할 수 있는 동적인 데이터이며, 값이 변경될 때마다 컴포넌트의 렌더링 결과물에 영향을 준다. 리액트 앱 내의 상태는 지역 상태, 전역 상태, 서버 상태로 분류할 수 있다. 리액트 내부 API만을 사용하여 상태를 관리할 수 있지만 성능 문제와 상태의 복잡성으로 인해
Redux, MobX, Recoil 같은 외부 상태 관리 라이브러리를 주로 활용한다.

1. 지역 상태(Local State)
: 지역 상태는 컴포넌트 내부에서 사용되는 상태로 예를 들어 체크박스의 체크 여부나 폼의 입력값 등이 해당한다. 주로 useState 훅을 가장 많이 사용하며 때에 따라 useReducer와 같은 훅을 사용하기도 한다.

2. 전역 상태(Global State)
: 전역 상태는 앱 전체에서 공유하는 상태를 의미한다. 여러 개의 컴포넌트가 전역 상태를 사용할 수 있으며 상태가 변경되면 컴포넌트들도 업데이트된다 .또한 Prop drilling 문제를 피하고자 지역 상태를 해당 컴포넌트들 사이의 전역 상태로 공유할 수도 있다.

3. 서버 상태(Server STate)
: 서버 상태는 사용자 정보, 글 목록 등 외부 서버에 저장해야 하는 상태들을 의미한다. UI 상태와 결합하여 관리하게 되며 로딩 여부나 에러 상태 등을
포함한다. 서버 상태는 지역 상태 훅은 전역 상태와 동일한 방법으로 관리되며 최근에는 react-query, SWR같은 외부 라이브러리를 사용하여 관리하기도 한다.

[SWC와 Bable]
Babel
Babel 은 자바스크립트의 컴파일러입니다. 하는 역할로는 최신 Ecama Script 문법을 구형 버전으로 바꿔주는 역할을 하고 최적화 또한 해줍니다. 자바스크립트는 문제가 많은 언어입니다. 만든 기간은 2주일도 안되어서 세상에 급하게 나왔습니다. 때문에 버그들도 많고 개선해야 할 것들이 많습니다. 때문에 기술의 변화가 굉장히 빠르기 때문에 최신 브라우저조차 지원하지 못하는 문법과 기술들이 출현하고 있습니다.

이러한 상황으로인해 웹 개발자라면 옛날 브라우저를 사용하는 사용자들도 고려를 해야합니다. 이때 바벨은 새로운 문법이나 타입스크립트 혹은 JSX같이 다른 언어들에 대해서도 Ecma Script로 동작할 수 있도록 하위버전의 자바스크립트로 변환을 해줍니다.

바벨의 동작은 다음과 같습니다.

파싱 (parsing) : 코드를 읽고 추상 구문 트리(AST)로 변환하는 단계
출력 (printing) : 변경된 결과물을 출력하는 단계
파싱과정을 통해 고수준의 인간의 언어에서 저수준의 기계어로 변환을 합니다. 바벨은 자바스크립트 코드를 받아 AST를 만듭니다. 그리고 이것을 활용하여 새로운 자바스크립트 코드를 출력합니다.

SWC (Speedy Web Compiler)
SWC 는 자바스크립트 프로젝트의 컴파일과 번들링 모두에 사용할 수 있는, Rust라는 언어로 제작된 빌드 툴입니다. SWC는 Speedy Web Compoiler의 약자로, 말 그대로 매우 빠른 웹 컴파일러의 기능을 제공하는 툴입니다.

하지만 실제로는 컴파일의 기능만을 제공하는 것은 아닙니다. 웹팩과 같이 자바스크립트의 기능도 제공하려고 개발을 하고 있습니다. 얼마든지 기능 확장이 가능하도록 설계되어 있기 때문에, 단순한 컴파일러가 아닌 하나의 플랫폼으로 보는 것이 적절할 것 같습니다.

SWC 프로젝트의 목표는 다음과 같습니다. 개발자이신 강동윤님의 말을 따르면 느린 웹 빌드 툴 전체를 러스트로 다시 구현하는 것 이기 때문에 앞으로도 SWC의 기능은 추가될 것으로 보입니다.

기존에 사용하는 자바스크립트는 이벤트 루프 기반의 싱글 스레드를 사용합니다. 하나의 일 밖에 못하는 것입니다. 하지만 SWC 언어는 Rust 프로그래밍 언어는 병렬 처리를 고려하여 설계된 언어이기 때문에 멀티 스레드를 사용이 가능합니다. 여러 일을 동시에 할 수 있습니다.

싱글 스레드, 멀티 스레드 차이때문에 속도가 빠른거다? 그뿐만이 아닙니다. 싱글 스레드 환경에서도 SWC가 바벨보다 20배가 더 빠르다는 벤치마크의 결과도 있습니다.
```

<br>
<br>

## 2025.01.19 (Sun)

### ✅ Today I've done

-   타입 좁히기 -> 타입 가드
-   Axios 활용하기
-   NextAPiHandler 활용하기
-   리액트 훅
-   온보딩 뷰 개발해보기

<br>

### ❣️ Today I've Learned

```
[타입 가드]
- 타입스크립트에서 타입 좁히기는 변수 또는 표현식의 타입 범위를 더 작은 범위로 좁혀나가는 과정을 말한다.
타입 좁히기를 통해 더 정확하고 명시적인 타입 추론을 할 수 있게 되고, 복잡한 타입을 작은 범위로 축소하여 타입 안정성을 높일 수 있다.

1. 타입 가드에 따라 분기 처리하기
타입 스크립트에서의 분기 처리는 조건문가 타입 가드를 활용하여 변수나 표현식의 타입 범위를 좁혀 다양한 상황에 따라 다른 동작을 수행하는 것을 말함.
타입 가드는 런타임에 조건문을 사용하여 타입을 검사하고 타입 범위를 좁혀주는 기능을 말한다.

[Axios 활용하기]
- fetch는 내장 라이브러리이기 때문에 따로 임포트하거나 설치할 필요 없이 사용할 수 있다.
그러나 많은 기능을 사용하려면 직접 구현해서 사용해야 한다. 이러한 번거로움 떄문에 Fetch 함수를 직접 쓰는 대신 Axios 라이브러리를 사용하고 있다.

각 서버(주문을 처리하는 서버와 장바구니를 처리하는 서버)가 담당하는 부분이 다르거나 새로운 프로젝트의 일부로 포함될 때 기존에 사용하는 API Entry(Base URL)와는
다른 새로운 URL로 요청해야 하는 상황이 생길 수 있음.

이렇게 API Entry가 2개 이상일 경우에는 각 서버의 기본 URL을 호출하도록 2개 이상의 API 요청을 처리하는 인스턴스를 따로 구성해야 한다.
이후 다른 URL로 서비스 코드를 호출할 때는 각각의 requester를 사용하면 된다.

[NextApiHandle 활용하기]
- 프로젝트에서 Next.js를 사용하고 있다면 NextApiHandler를 활용할 수 있다. NExtApiHandler는 하나의 파일 안에 하나의 핸들러를
디폴트 익스포트로 구현해야 하며 파일의 경로가 요청 경로가 된다.
핸들러를 정의하는 것은 간단하다. 응답하고자 하는 값을 정의하고 핸들러 안에서 요청에 대한 응답을 정의한다. 핸들러를 사용하는 경우
단순히 파일을 불러오는 것과 다르게 중간 과정에 응답 처리 로직을 추가할 수 있다.

[리액트 훅]
- 리액트에 훅이 추가되기 이전에는 클래스 컴포넌트에서만 상태를 가질 수 있었다. 클래스 컴포넌트에서는 componentDidMount, componentDidUpdate와 같이
하나의 생명주기 함수에서만 상태 업데이트에 따른 로직을 실행시킬 수 있었음. 간단한 형태의 컴포넌트에서는 문제가 되지 않았지만, 프로젝트 규모가
커지면서 상태를 스토어에 연결하거나 비슷한 로직을 가진 상태 업데이트 및 사이드 이펙트 처리가 불편해졌다. 또한 모든 사앹르 랗나의 함수 내에서 처리하다 보니 관심사가 뒤섞이게 되었고 상태에 따른 테스트나 잘못 발생한 사이드 이펙트의 디버깅이 어려워졌다.

1. useState
리액트 함수 컴포넌트에서 상태를 관리하기 위해 useState 훅을 활용할 수 있다.


```

<br>
<br>

## 2025.01.18 (Sat)

### ✅ Today I've done

-   타입스크립트
-   로그인 페이지(우리 서비스의 index view) 개발

<br>

### ❣️ Today I've Learned

```
TypeScript는 마이크로소프트가 공개한 자바스크립트의 슈퍼셋 언어.
Dart(구글이 자바스크립트를 대체하기 위해 제시한 새로운 언어)와 달리 자바스크립트 코드를 그대로 사용할 수 있었고, 아래와 같은 단점을 극복할 수 있었기 때문에 많은 환영을 받았다.

*슈퍼셋(Superset) : 기존 언어에 새로운 기능과 문법을 추가해서 보완하거나 향상하는 것을 말한다. 슈퍼셋 언어는 기존 언어와 호환되며 일반적으로 컴파일러 등으로 기존 언어 코드로 변환되어 실행됨.

1) 안정성 보장
- 타입스크립트는 정적 타이핑을 제공. 컴파일 단계에서 타입 검사를 해주기 때문에 자바스크립트를 사용했을 때 빈번하게 발생하는
타입 에러를 줄일 수 있고, 런타임 에러를 사전에 방지할 수 있어 안정성이 크게 높아짐.

2) 개발 생산성 향상
- VSCode 등의 IDE(VSCode는 엄밀히 텍스트 에디터이긴 하지만..) 타입 자동 완성 기능을 제공함. 이 기능으로 변수와 함수 타입을
추론할 수 있고, 리액트를 사용할 때 어떤 prop을 넘겨야 하는지 매번 확인하지 않아도 사용부에서 바로 볼 수 있기 때문에 개발 생산성이
크게 향상됨

3) 협업에 유리
- 타입스크립트를 사용하면 복잡한 애플리케이션 개발/협업에 유리. 타입스크립트는 인터페이스, 제네릭 등을 지원하는데 인터페이스가
기술되면 코드를 더 쉽게 이해할 수 있게 도와줌. 또한 복잡한 애플리케이션일수록 협업하는 개발자 수도 증가하는데 자동 완성 기능이나
기술된 인터페이스로 코드를 쉽게 파악할 수 있음.

*타입스크립트 인터페이스 : 객체 구조를 정의하는 역할. 다시 말해 특정 객체가 가져야 하는 속성과 메서드의 집합을 인터페이스로 정의해서
객체가 그 구조를 따르게 함.

4) 자바스크립트에 점진적으로 적용 가능
- 타입스크립트는 자바스크립트의 슈퍼셋이기 때문에 일괄 전환이 아닌 점진적 도입이 가능하다. 전체 프로젝트가 아닌 일부 프로젝트,
그중에서도 일부 기능부터 점진적으로 도입해볼 수 있음. 우아한형제들도 주문 접수 앱 웹 뷰의 새 긴으에 리액트와 타입스크립트를
선제적으로 적용해본 후에 대대적으로 리액트 + 타입스크립트로 개편하는 전략을 사용했다.
```

<br>
<br>

## 2025.01.17 (Fri)

### ✅ Today I've done

-   UI/UX 디자인 회의
-   **React** 프로젝트 생성 및 환경설정
-   **왜 React를 써야만 하는가?** 근거 수집/분석
-   로그인 페이지 구현 방식 공부
-   온보딩 뷰 UI/UX 고민

<br>

### ❣️ Today I've Learned

```
오늘은 1가지 큰 주제에 대해서 고민하고 배운 순간이었다.
왜 React를 써야 하는가로 시작하여, 왜 Next.js의 OOO을 써야 하는지를
하루종일 고민하고 근거를 수집하고 분석하였다.

우선 아래와 같이 선택의 근거를 정리하기로 하였다.
- 바닐라의 형태로 html, css, Javascript로만 쓸 필요는 없는가?
- 그러면 왜 React로 하는 게 나을까? Frontend의 다른 라이브러리/프레임워크는 선택지가 아닌가?
- React를 사용한다고 하면, Next.js를 선택하게 되면, 어떤 점이 좋을까?
- Next.js가 현재 어떤 버전까지 나왔으며, 무슨 버전을 선택하는 것이 우리의 개발에 유리할까?
- App router 기반으로 해야 할까? Pages router 기반으로 해야 할까?
- 하드웨어 리소스랑 서버는 불변의 상황이라고 가정할 때, 프론트에서 성능을 개선할 방법이 있을까?
- 프론트에서 성능을 개선한다면 App router는 효과적일까?
- Next.js는 기본적으로 Webpack이라는 Build tool(Bundler)을 지원하고 있지만 다른 선택지는 어떨까?

위와 같은 질문에 대한 답변을 찾아가며 오늘 하루 공부한 내용을 정리할 수 있었다.
그 중에서 Next.js 13 버전을 선택하고 알게 된 점이 있었는데 15 버전이 출시되면서 13에서 발견된 3가지의 큰 보안 취약점이 있었는데 그 부분을 GPT를 통해 정리하면서 TIL을 마무리하겠다!

1. Next.js Server-Side Request Forgery (SSRF) in Server Actions
- 서버 액션(서버 컴포넌트 및 API 라우트 등)에서 외부로 HTTP 요청을 보낼 때, 공격자가 의도치 않은 서버 내부 자원에 접근하게 만들 수 있는 취약점입니다.
- SSRF는 서버가 내부망이나 다른 서버로 임의의 요청을 보내도록 유도할 수 있어서, 심각한 보안 문제로 이어질 수 있습니다.

2. Denial of Service (DoS) in Next.js image optimization
- Next.js에서 제공하는 이미지 최적화 기능(`next/image`)을 악의적으로 이용해, 서버 리소스를 과도하게 점유할 수 있는 문제가 보고되었습니다.
- 결과적으로 서버가 정상적인 사용자 요청에 응답하지 못하게 되는, 서비스 거부(DoS) 상태가 초래될 수 있습니다.

3. Next.js authorization bypass vulnerability
- Next.js 애플리케이션에서 권한 검증이 의도대로 동작하지 않아, 공격자가 인증 없이 특정 페이지나 API에 접근할 수 있는 위험이 존재합니다.
- 이는 사용자 정보 노출, 무단 조작 등의 심각한 보안 사고로 이어질 수 있습니다.
```

<br>
<br>

## 2025.01.16 (Thu)

### ✅ Today I've Done

-   기획 일부 수정
-   **와이어 프레임** 수정
-   **React** 프로젝트 구조 설계
-   FE 역할 분담
-   Jira **백로그** 작성
-   **[SSAFY]** Figma 디자인 특강
-   **React** 공부

<br>
 
### ❣️ Today I've Learned
```
기획적으로 부족한 부분이 계속 생겨 오늘도 기획을 수정하였다.

이에 따라, 화면 설계/레이아웃 배치를 새로 하였다.

화면 설계/레이아웃 배치를 수정하는 과정에서 유저 서비스 플로우 관점에서 부족한 부분이 다시 노출되었고, 특히 WebRTC를 사용한 1-on-1 Video Calling 서비스에서 서로의 시간을 Fix하는 부분에서 결함이 있었다.

해당 결함은 Gift Receiver의 경우, Video Calling Time이 Fix되지만 Sender의 경우 시간이 확정되지 않는 문제가 발생할 수도 있었다.

FE에서 프로젝트 구조 설계가 끝났다. 그래서 비슷한 역할을 할 수 있는 카테고리를 다음과 같이 6개의 대분류로 정리하였다.

-   메인, 로그인/튜토리얼, 편지, 선물/선물함, 채팅, Video calling

상기와 같은 대분류에서 작업량을 러프하게 의논하여 보고, View 페이지를 기준으로 역할을 분담하였다. 결과적으로 Jira에는 Component 단위로 백로그를 작성할 수 있었다.

또한, 전국 단위에서 Jira 프로젝트 현황을 확인할 수 있었는데 서울 6반 3팀(A603)인 우리가 Jira 이슈의 개수가 201개로 1등을 차지하고 있었던 점이 인상 깊었다. 아무래도 프로젝트를 성공적으로 마무리 할 수 있다라는 전조 현상이 아닐까 싶다. 협업 툴을 효과적이고 효율적으로 쓸 수 있는 방향으로 지속적인 고민을 해야 할 것 같다.

오늘 Figma 디자인 특강에서는 프로토타입을 중점적으로 배울 수 있었고, IT 서비스 회사의 Design System을 사용할 수 있는 Resources에 대해서 파악할 수 있었다.

```

<br>
<br>

## 2025.01.15 (Wed)

### ✅ Today I've Done
- 레이아웃 완성
- **React** 프로젝트 구조 설계
- 유저 유입 유도 및 리텐션 확대 방안 고민
- 인앱 브라우저에서 외부 브라우저로 강제 전환 방법 공부
- 웹 서비스에서 모바일 디바이스 접근하여 카메라 촬영 구현 공부
- **[SSAFY]** Figma 디자인 특강
- **React** 공부

<br>


### ❣️ Today I've Learned
```

오늘은 완성된 화면 설계를 바탕으로 레이아웃을 최대한 Fix하기로 하였고, 우선 레이아웃까지도 마무리되었다.

그렇게 React 프로젝트 구조 설계를 시작할 수 있었다.
어제 오프닝을 하고 시작하였지만 바뀌는 부분이 존재하여 다시 pages, components를 살펴보기로 하였다.
프로젝트 구조 설계를 내일까지는 끝내야 역할 분담, Jira 백로그 작성이 가능하다고 판단하였고, 우리의 프로젝트 작업량을 빠르게 그려볼 수 있다고 생각했다. (우리는 빠른 개발이 중요한 프로젝트라는 점이 핵심이다...)

이후에는 유저 유입 유도 및 리텐션 확대 방안을 고민해보았다.

새로 유입되는 사용자들에게 서비스를 더 잘 소개하고, 어떻게 하면 지속적으로 서비스를 이용하게 할 수 있을까?
링크 공유, 온보딩, 재화 획득 방식을 제공하는 방식을 토대로 극복해보자고 결정하였다.

다음으로는 링크 공유 시 발생하는 인앱 브라우저에서 확인하는 사용자들에 대해서 외부 브라우저인 우리 서비스로 강제 전환 방법이 필요하였다.

이 부분에 대해서는 스키마(URI Scheme)나 Intent 기능을 사용하면, 버튼 클릭 시 외부 브라우저로 전환할 수 있다.
구현 시 OS별 (iOS/Android) 호환성을 고려해야 하고, 사용자가 설치한 브라우저 중 어떤 브라우저로 열지 선택하도록 처리할 수도 있다.

최근에 정리한 자료이기도 하지만 웹 서비스에서 모바일 디바이스 접근하여 카메라 촬영 구현하는 방식에 대해서 MDN 공식 문서를 조금 더 찾아보았다. 거기서 Media Capture and Streams API (Media Stream)가 어떻게 구성되고 있는지 살펴볼 수 있었다.

아울러, 권한 관리가 중요한데, 모바일 디바이스마다 권한 요청 UX/UI가 다르고, 브라우저에서 HTTPS 환경이 필수일 수 있다.
사용자 경험을 최대화하기 위해, 카메라를 직접 열어서 사진을 촬영할지, 앨범에서 이미지를 가져올지 선택할 수 있도록 설계하는 것은 아직 고민 중에 있고, Capture를 통해 네이티브 앱인 카메라로 촬영한 것처럼 구현하는 것도 같은 고민 안에 있다.

오늘 Figma 특강에서는 왜 Figma를 쓰는 것이 편한지 파악할 수 있는 시간이었고, 각 요소별 소개가 포함되었다.

```

<br>
<br>

## 2025.01.14 (Tue)

### ✅ Today I've Done
- 기획 일부 수정
- 요구사항 수집/분석
- **와이어프레임** 작성
- 카카오톡 알림 API 공부
- 미팅 w/ 컨설턴트님, 실습코치님
- Backend 챌린지 고민
- **[SSAFY]** Figma 디자인 특강
- **React** 공부

<br>


### ❣️ Today I've Learned

```

지속적으로 기획이 수정되고 있으며, 이에 따라 추가적인 요구사항을 수집하고 분석하는 과정이 진행되고 있습니다.
Frontend에서는 A/B Testing을 통해 어떤 방식이 더욱 Fit할지 고민하고 있습니다.

그리고 오늘은 컨설턴트님과 실습코치님과 함꼐 미팅이 있었습니다. 이때, Backend가 프로젝트 진행하는 기간 동안 볼륨이 작아보일 수도 있다는 우려에 대해서 얘기가 나왔고 고민해보는 시간을 가질수 있었습니다.

Backend 챌린지는 다양한 방식으로 접근할 수 있다고 생각했습니다. 볼륨이 작더라도, 내가 어느 정도 Depth까지 연구를 해봤는가? 이미 만들어진 API가 아닌 내가 기술을 직접 찾아보고 기술을 구현할 수도 있을까? 시도를 해봤나? 등에 대한 생각이 들었습니다. 그렇지만, 짧은 프로젝트 기간 동안 Depth를 파고드는 것도 중요하지만, 확장성도 충분히 고려해보았을 때, 새로운 기술을 사용하는 시간에 대해서도 긍정적으로 접근해볼 수 있다고 배울 수 있었던 시간이었습니다.

오늘부터는 Figma 디자인 특강이 시작됐습니다. 오늘은 교육용 계정을 받아 Unlimited project 생성, Dev mode 사용 가능이 가능해졌고, 이를 토대로 간단히 Figma는 어떻게 구성되고 기능을 어떻게 활용할 수 있는지 튜토리얼 시간을 가졌습니다. Figma를 시작할 때는 당장에는 공부할 생각을 크게 하지 못했는데 시작부터 다시 공부를 하는 부분에 있어서 내가 놓쳤던 부분을 생각해볼 수 있었던 강의였습니다. 가장 인상 깊었던 부분은 Figma AI이며, Figma AI를 사용하게 되면 Frontend는 사라질까? 라고 먼저 생각이 들겠지만 저는 Frontend에서 개발 속도를 단축하면 어떤 부분을 더 Depth를 가지고 파고들 수 있을까? 같은 시간 대비 퀄리티는 더욱 좋아지겠구나 라는 생각이 먼저 들었던 시간이었습니다.

끝으로 카카오톡 알림 API에 대해서 공부한 내용을 아래와 같이 정리해보았다.

1. 비즈니스 채널 연동

카카오 비즈니스 채널과 연동하기 위해서는 먼저 채널 개설 및 앱 연결이 필수다.
카카오 디벨로퍼스 사이트에서 앱을 등록한 뒤, 해당 앱을 채널과 연결해야 원하는 서비스에서 메시지를 보낼 수 있다.

2. 메시지 템플릿 설정

카카오 알림톡은 ‘비즈 메시지’로 취급되어, 특정 템플릿 검수가 필요하다.
메시지 내용이나 버튼 등을 미리 템플릿으로 등록해두고, 승인된 템플릿을 이용해야만 발송 가능하다.

3. 인증 토큰 발급

API를 통해 메시지를 전송하기 위해서는 액세스 토큰이 필요하다.
발급받은 REST API Key와 Redirect URI 등을 활용해 OAuth2 인증 과정을 거쳐 토큰을 가져온 뒤, 이를 통해 메시지 전송 요청을 한다.

4. 알림 메시지 전송 프로세스

사용자 정보(전화번호, 수신 동의 상태 등)를 확인하고, 인증에 사용될 토큰을 적용해, 실제 메시지 전송 API를 호출하여 알림톡을 발송한다.

5. 주의할 점

알림톡은 광고성 메시지 여부 등에 따라 규정이 까다로울 수 있으므로, 사전에 가이드라인을 숙지해야 한다.
템플릿 검수에 통과해야만 실제 서비스 환경에서 발송할 수 있으므로, 준비 단계에서 메시지 문구를 꼼꼼히 검토하는 것이 중요하다.

```

<br>
<br>

## 2025.01.13 (Mon)

### ✅ Today I've Done
- 기획/아이디어 회의
- 요구사항 수집/분석
- **와이어프레임** 작성
- **디자인 UI/UX** 공부
- **React** 공부

<br>


### ❣️ Today I've Learned

```

원래는 이번 주부터 아이디어 회의를 포함한 기획 주간이지만, 지난주에 아이디어는 결정되어 있었다.

그래서 기획을 잠정적으로 확정하고, 지난주 주중/주말을 이용하여 러프하게 화면 설계를 했었던 와이어프레임을 추가적으로 보완하기 시작했다.

와이어프레임 내에서 레이아웃은 우선순위를 뒤로 미뤄서 배치하기로 하고, 화면 설계를 최대한 확정지을 수 있도록 목표를 설정하여 작업하였다.

이 과정에서 Figma를 어떻게 하면 효과적으로 쓸 수 있을까? 하는 고민이 많았던 것 같다. 미리 추가로 얘기하자면 Frontend 관점에서 어떤 기능들이 필요할지 세부적으로 파악하는 계기가 되었다.

그럼 무엇을 Figma로 배웠는지 아래와 같이 정리해보았다.

-   Plugins 활용
-   UI Kit 활용
-   Section/Frame의 구분
-   Auto layout
-   Dev mode

그리고 우리 "초코레터(Chocoletter)" 서비스에서 유저들을 유입시킬 수 있는 핵심 포인트 및 유저 리텐션을 늘릴 수 있는 포인트가 UI/UX 디자인 비중이 상당히 높게 평가될 것 같다.

그래서 디자인 비중이 높아지게 되면 왜 디자인이 예뻐야 사용자가 유입된다고 생각하는지를 고려하면서 UI 기본 용어부터 공부하였다.

```

```
