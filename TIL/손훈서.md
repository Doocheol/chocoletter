### 1/13 (월)
---
#### Jenkins (vs github action)

- github action은 해당 레포지토리에서 직접 트리거할 수 있다. 

```yaml
on:  
  push:  
    branches:  
      - "main"  
```

- jenkins는 jenkins에 gitlab crediential 설정(use, gitlab access token)을 하고, gitlab에서 webhook 설정(use, jenkins secret token)을 해서 작업을 트리거할 수 있다.

### 1/14 (화)
---
#### 특정 요소(resource)의 pk를 url에 직접 노출 시켜도 될까?

> 당연히 안된다. ([전북대 사례](https://www.youtube.com/watch?v=WxT6JB5ob44))

- 왜? ([참고자료](https://kyu-nahc.tistory.com/entry/Spring-boot-PK-Id-%EB%85%B8%EC%B6%9C%EC%9D%84-%EB%A7%89%EB%8A%94-Rest-API))
	1. 리소스 주소 노출로 인한 보안 취약성
	2. Auto Increment 패턴 노출

- 그럼 어떻게? -> Java AES 대칭키 ([참고자료](https://kyu-nahc.tistory.com/entry/Spring-boot-PK-Id-%EB%85%B8%EC%B6%9C%EC%9D%84-%EB%A7%89%EB%8A%94-Rest-API))
	- 이를 프로젝트 구현할 때, 적용해보자

#### 특정 회사마다의 컨벤션이 따로 존재하며, 이를 참고한다면 협업의 능률이 오를 수 있다는 것을 알게되었다.

- [참고자료](https://bestinu.tistory.com/64)

### 1/15 (수)
---
#### 채팅 서비스를 구현하기 위해 고려해야할 점들

1. 도입하여야할 기술
	- 웹소켓: 기존의 http 통신은 비연결성, 연결성이 존재하는 통신을 위함
	- NoSQL: 확장성, 지연시간
	- 메시지큐: 유실방지, 순서보장
2. 서버 분리: 채팅 서버에 문제가 생겼을 때, 코어 서비스 서버에 문제가 생기면 안되기 때문
3. 샌드버드와 같은 외부 서비스를 이용하는 방법도 존재

### 1/16 (목)
---
#### 2025-01-16 17:00 시점 설정

- gitlab에 대한 crediential 설정은 아무것도 안한 상태
	- webhook 설정은 했다. -> jenkins에서 얻은 secret token을 gitlab webhook에 올림
- ssh에 대한 crediential 설정만 되어있는 상태
- `Build Steps` 에서 `Execute shell` 을 선택하여 gitlab 인증의 경우 아래처럼 clone 명령어를 쓸 때 파라미터로 oaurth2를 사용하여 인증하였음 (다소 rough)

```shell
git clone -b BE_dev --single-branch https://oauth2:${GITLAB_TOKEN}@lab.ssafy.com/s12-webmobile1-sub1/S12P11A603.git ${SERVER_NAME}
```

> 이 방법이 rough 해서 썩 좋아보이진 않는다, crediential 로 설정이 되게 하는 방법이 나을듯 ???

#### After this

- Q1) Gitlab Crediential 세팅은 Execute shell에서 직접 clone할 때는 적용이 안되는건가?
- Q2) 만약, 그렇다면 Gitlab Crediential을 적용해서, 인증 후 clone하는 건 어떻게??

- cf) clone 을 할때, http 방법과 ssh 방법이 있는데, 싸피 내부망(깃랩)은 ssh 즉, 22 포트는 막혀있다.
	- 진행하면서 ssafy 내부망은 443, 80포트만 열려있는 것을 알게되었다. (22, 8080 등 모두 막혀있음)

### 1/17 (금)
---
#### Jenkins Issue

1. 특정 브랜치의 이벤트에 트리거
	- `Triggers` -> 고급 -> `Allowed branches` 에서 -> Filter branches by name을 하면 잘 안됨 (Filter branches by regex)로 하자

#### AWS EC2 포트포워딩

1. 포트 포워딩 추가
	- 80 포트 -> 8080
```bash
sudo iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8080
```

> 위처럼 하면 문제가 생길 수 있다. -> eth0
> 
> AWS 등 각 서버마다 네트워크 인터페이스가 다를 수도 있다. (eth0, enX0 등) 따라서 모든 인터페이스에 적용되는 아래와 같이 설정해야한다.

```shell
sudo iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080
```

2. 포트 포워딩 확인
```bash
sudo iptables -t nat -L --line-numbers
```

3. 포트 포워딩 삭제
```bash
sudo iptables -t nat -D PREROUTING {삭제할 번호}
```

### 1/20 (월)
---
#### 여러 환경에서의 배포

> 현재 aws rds를 외부에서 접속하지 못하게 막아뒀다.
> 
> 실제 product 서버는 rds와 서브넷으로 연결된 ec2에 배포할 것이기 때문에, 큰 문제가 없지만, dev 혹은 test 서버는 rds에 접근할 때, 연결된 ec2 서버를 마치 프록시서버처럼 사용하는 터널링을 사용해서 접근해야한다.

- PROBLEM) 터널링을 통해 외부의 접근이 차단된 aws rds에 test서버를 연결(서브넷으로 연결된 ec2로 터널링하는 방법으로)하는 도중에 ssh 인증 오류가 생겼다.

- SOLUTION) 결국에 Spring 백엔드 서버에서 ssh로 터널링 서버로 접속해야하는 것이기 때문에, 해당 백엔드 서버 컨테이너 안으로 pem키를 옮긴 후, 해당 컨테이너 안에서 접속을 진행해야한다.
	- 이전에 나는 컨테이너 내부가 아닌 컨테이너를 가진 서버에 pem키를 넣어뒀기 때문에 당연히 안됐다.

#### Nginx에서 SSL 인증을 하는 여러 방법

##### 1. 인증서 파일 직접 등록

- 수정해야할 파일
```bash
sudo nano /etc/nginx/sites-available/default
```

- 인증키, 중간키 합치기
```bash
cat 인증키.crt 중간키.crt >> combined.crt
```

아래 설정파일 기능
- 80 포트도 443 리다이렉트
- ssl 인증서 설정

```nginx
server {
    listen 80;
    server_name api.chocoletter.store;

    # HTTP를 HTTPS로 리다이렉트
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl;
    server_name api.chocoletter.store;

    # SSL 인증서 설정
    ssl_certificate /home/ubuntu/ssl/combined.crt; # 인증키와 중간키를 합친 것으로 사용해야함함
    ssl_certificate_key /home/ubuntu/ssl/private.key;

    # SSL 설정 최적화            
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GC";
    ssl_prefer_server_ciphers off;

    # SSL 세션 캐시 설정
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;
    ssl_session_tickets off;

    # HSTS 설정
    add_header Strict-Transport-Security "max-age=63072000" always;

    location / {
        proxy_pass http://localhost:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

- nginx 문법 검사
```bash
sudo nginx -t
```

- nginx 재시작
```bash
sudo systemctl restart nginx
```

##### 2. certbot (lets encrypt)

1. 직접 키를 생성하고 nginx conf 파일 수정해주기
```bash
sudo apt-get install certbot
```

```bash
sudo certbot certonly \
  --manual \
  --email thsgnstj0512@gmail.com \
  --agree-tos \
  -d chocoletter.store \
  -d *.chocoletter.store
```

- 위로 생긴, 인증서의 경로를 nginx에 등록해주면 된다.

2. nginx certbot으로 자동으로 하기
```bash
sudo apt-get install certbot python3-certbot-nginx
```

```bash
sudo certbot --nginx \
  --email thsgnstj0512@gmail.com \
  --agree-tos \
  -d api.chocoletter.store
```

>  인증을 할때, nginx conf 파일의 `server_name`을 참조하기 때문에 `-d`에 들어가는 내용과 nginx conf 의 `server_name`이 같아야 한다.

### 1/21 (화)
---
#### SSH 인증(개인키, 공개키)의 정확한 원리

1. **초기 연결**
    - 클라이언트가 서버에 SSH 연결 시도
    - 서버는 자신의 공개키를 클라이언트에게 전송
    - 클라이언트는 서버 공개키의 신뢰성 확인 (known_hosts 파일 체크)
2. **세션키 교환**
    - 클라이언트가 임의의 세션키를 생성
    - 이 세션키를 서버의 공개키로 암호화하여 서버에 전송
    - 서버는 자신의 개인키로 복호화하여 세션키를 얻음
    - 이후 통신은 이 세션키로 암호화됨
3. **인증 과정**
    - 서버가 랜덤 challenge 생성
    - 클라이언트는 자신의 개인키로 이 challenge에 서명
    - 서버는 클라이언트의 공개키(authorized_keys에 저장된)로 서명 검증

#### A 와 CNAME

> A: 타겟 ip
> CNAME: 이동시켜야하는 도메인

- PROBLEM) A태그와 CNAME이 같은 곳을 가리키고 있었다.
- 설정 도메인: `chocoletter.store`
	- 할당: `api.chocoletter.store`
		- A태그: 111.111.111.111
		- CNAME태그: `api.chocoletter.store.`
	- 다른 서브도메인도 마찬가지

- 위처럼 설정되어있으면, 아래와 같은 오류들이 발생한다.

- 1. **충돌**: A 레코드와 CNAME 레코드가 동일한 도메인을 가리키도록 설정되면 충돌이 발생할 수 있습니다. DNS 표준에 따르면 하나의 도메인에는 A 레코드와 CNAME 레코드가 공존할 수 없습니다. A 레코드와 CNAME 레코드가 동일한 이름에 대해 설정되면 DNS 서버가 이를 처리할 수 없게 되며 DNS 조회에 실패할 수 있습니다.

- 2 **비예측성**: A 레코드와 CNAME 레코드 사이에 설정된 경로가 서로 다른 IP 주소, 혹은 상이한 결과를 가리키게 되어 비예측적인 동작을 초래할 수 있습니다. 이러한 설정은 서버와 사용자의 연결에 혼란을 줄 수 있습니다.

- 3. **버그 및 오작동**: 많은 DNS 서비스 제공자나 클라이언트 소프트웨어는 A 레코드와 CNAME이 동일한 지점을 가리킬 때 버그나 성능 문제가 발생할 수 있도록 설계되어 있지 않습니다. 따라서 서비스 제공자의 설정에 따라 시스템과 클라이언트가 오작동할 수 있습니다.

### 1/22 (수)
---
#### 프론트 엔드 빌드, 배포 최적화

1. 배포할 때, 베이스 이미지를 `node` 말고 `node-alpine`을 쓰자. (경량화)
	- ex) `node:22-alpine`

2. `npm install` vs `npm ci`
	- node_modules 폴더를 삭제하여 깨끗한 상태를 보장한다.
	- 그러면 package-lock.json에서 정확한 버전의 모든 종속성을 설치한다.
	- npm install과는 달리 npm ci는 package-lock.json을 수정하지 않는다.
	- **그러나 프로젝트에 package-lock.json 파일이 있어야 한다.**
	- 이 파일이 없으면 npm ci가 작동하지 않으므로 대신 npm install을 사용해야 한다.
	- npm ci를 사용하면 안정적인 빌드를 얻을 수 있다.
	- 이 기능은 Jenkins 또는 GitLab CI와 같은 연속 통합 도구에서 실행할 때 유용하다.
	- [출처](https://doqtqu.tistory.com/353)

### 1/23 (목)
---
#### Spring Security Basic

구성요소
1. Spring Security (Filters)
	- 인증이 필요한지 판단, 필요 o -> 로그인페이지와 같은 인증 페이지 / 필요 x -> pass
2. Authentification
	- ex) `UsernamePasswordAuthentificationFilter` 는 요청에서 id, password 추출 (-> 세부 정보 추출 로직)
3. Authentification Manager
	- 인증 관리자, 세부인증 Provider에 위임
	- 마치 스프링의 Dispatcher Servlet과 비슷한 느낌?
4. Authentification Providers
	- 실제 인증을 진행하는 주체
	- 비유를 하자면 Authentification Providers 라는 인터페이스가 존재
	- 이에 대한 구현체들이 `UserDetailsManager`, `PasswordEncoder` 과 같은 것들이 존재하며 실제로 이것들이 인증 실행
5. Security Context
	- 인증 완료시 인증정보가 보관됨

### 1/24 (금)
---
#### 1. Openvidu의 구조

- 환경: 아무것도 설치되어있지 않은 서버에 docker와 openvidu만 설치한 상태
	- openvidu docs에서 nginx가 이미 설치되어있다면, 오류가 나므로 지운 상태에서 설치하기를 권장
	- [openvidu 배포 공식 docs](https://docs.openvidu.io/en/stable/deployment/ce/on-premises/)

- 컨테이너 상황 (`docker ps`)
```bash
CONTAINER ID   IMAGE                                COMMAND                  CREATED        STATUS                  PORTS                                                                                                      NAMES
0d06b422cea5   openvidu/openvidu-proxy:2.31.0       "/docker-entrypoint.…"   17 hours ago   Up 17 hours                                                                                                                        openvidu-nginx-1
3becc1d5b225   openvidu/openvidu-call:2.31.0        "docker-entrypoint.s…"   17 hours ago   Up 17 hours                                                                                                                        openvidu-app-1
0eb255d2dfd4   openvidu/openvidu-coturn:2.31.0      "docker-entrypoint.s…"   17 hours ago   Up 17 hours             0.0.0.0:3478->3478/tcp, 0.0.0.0:3478->3478/udp, :::3478->3478/tcp, :::3478->3478/udp, 5349/tcp, 5349/udp   openvidu-coturn-1
e3269fef0e3a   openvidu/openvidu-server:2.31.0      "/usr/local/bin/entr…"   17 hours ago   Up 17 hours                                                                                                                        openvidu-openvidu-server-1
dd8cf5a7d820   kurento/kurento-media-server:7.1.1   "/entrypoint.sh"         17 hours ago   Up 17 hours (healthy)                                                                                                              openvidu-kms-1
```

> Openvidu의 컨테이너들의 구조를 뜯어보자

##### 1.1. docker-compose.yml

```yml
version: '3.1'

services:

    openvidu-server:
        image: openvidu/openvidu-server:2.31.0
        restart: on-failure
        network_mode: host
        entrypoint: ['/usr/local/bin/entrypoint.sh']
        volumes:
            - ./coturn:/run/secrets/coturn
            - /var/run/docker.sock:/var/run/docker.sock
            - ${OPENVIDU_RECORDING_PATH}:${OPENVIDU_RECORDING_PATH}
            - ${OPENVIDU_RECORDING_CUSTOM_LAYOUT}:${OPENVIDU_RECORDING_CUSTOM_LAYOUT}
            - ${OPENVIDU_CDR_PATH}:${OPENVIDU_CDR_PATH}
        env_file:
            - .env
        environment:
            - SERVER_SSL_ENABLED=false
            - SERVER_PORT=5443
            - KMS_URIS=["ws://localhost:8888/kurento"]
            - COTURN_IP=${COTURN_IP:-auto-ipv4}
            - COTURN_PORT=${COTURN_PORT:-3478}
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

    kms:
        image: ${KMS_IMAGE:-kurento/kurento-media-server:7.1.1}
        restart: always
        network_mode: host
        ulimits:
          core: -1
        volumes:
            - /opt/openvidu/kms-crashes:/opt/openvidu/kms-crashes
            - ${OPENVIDU_RECORDING_PATH}:${OPENVIDU_RECORDING_PATH}
            - /opt/openvidu/kurento-logs:/opt/openvidu/kurento-logs
        environment:
            - KMS_MIN_PORT=40000
            - KMS_MAX_PORT=57000
            - GST_DEBUG=${KMS_DOCKER_ENV_GST_DEBUG:-}
            - KURENTO_LOG_FILE_SIZE=${KMS_DOCKER_ENV_KURENTO_LOG_FILE_SIZE:-100}
            - KURENTO_LOGS_PATH=/opt/openvidu/kurento-logs
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

    coturn:
        image: openvidu/openvidu-coturn:2.31.0
        restart: on-failure
        ports:
            - "${COTURN_PORT:-3478}:${COTURN_PORT:-3478}/tcp"
            - "${COTURN_PORT:-3478}:${COTURN_PORT:-3478}/udp"
        env_file:
            - .env
        volumes:
            - ./coturn:/run/secrets/coturn
        command:
            - --log-file=stdout
            - --listening-port=${COTURN_PORT:-3478}
            - --fingerprint
            - --min-port=${COTURN_MIN_PORT:-57001}
            - --max-port=${COTURN_MAX_PORT:-65535}
            - --realm=openvidu
            - --verbose
            - --use-auth-secret
            - --static-auth-secret=$${COTURN_SHARED_SECRET_KEY}
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"

    nginx:
        image: openvidu/openvidu-proxy:2.31.0
        restart: always
        network_mode: host
        volumes:
            - ./certificates:/etc/letsencrypt
            - ./owncert:/owncert
            - ./custom-nginx-vhosts:/etc/nginx/vhost.d/
            - ./custom-nginx-locations:/custom-nginx-locations
            - ${OPENVIDU_RECORDING_CUSTOM_LAYOUT}:/opt/openvidu/custom-layout
        environment:
            - DOMAIN_OR_PUBLIC_IP=${DOMAIN_OR_PUBLIC_IP}
            - CERTIFICATE_TYPE=${CERTIFICATE_TYPE}
            - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL}
            - PROXY_HTTP_PORT=${HTTP_PORT:-}
            - PROXY_HTTPS_PORT=${HTTPS_PORT:-}
            - PROXY_HTTPS_PROTOCOLS=${HTTPS_PROTOCOLS:-}
            - PROXY_HTTPS_CIPHERS=${HTTPS_CIPHERS:-}
            - PROXY_HTTPS_HSTS=${HTTPS_HSTS:-}
            - ALLOWED_ACCESS_TO_DASHBOARD=${ALLOWED_ACCESS_TO_DASHBOARD:-}
            - ALLOWED_ACCESS_TO_RESTAPI=${ALLOWED_ACCESS_TO_RESTAPI:-}
            - PROXY_MODE=CE
            - WITH_APP=true
            - SUPPORT_DEPRECATED_API=${SUPPORT_DEPRECATED_API:-false}
            - REDIRECT_WWW=${REDIRECT_WWW:-false}
            - WORKER_CONNECTIONS=${WORKER_CONNECTIONS:-10240}
            - PUBLIC_IP=${PROXY_PUBLIC_IP:-auto-ipv4}
        logging:
            options:
                max-size: "${DOCKER_LOGS_MAX_SIZE:-100M}"
```

##### 1.2. openvidu-server 컨테이너

- **역할**: OpenVidu 핵심 서버 (세션 관리, REST API 제공)
- **내부 통신**:
    - **KMS**와 통신: `ws://localhost:8888/kurento` (WebSocket)
    - **Coturn**과 통신: 환경변수(`COTURN_IP`, `COTURN_PORT`) 기반
- **외부 노출 포트**:
    - `5443` 포트 (HTTP, `SERVER_SSL_ENABLED=false` 설정 시)
    - 주로 내부 프록시(nginx)를 통해 외부에 노출됨
- **특징**:
    - 호스트 네트워크 사용(`network_mode: host`)
    - 볼륨을 통해 녹화 파일, CDR 데이터 저장
    - `.env` 파일에서 주요 설정 값 로드

##### 1.3. kms (Kurento Media Server) 컨테이너

- **역할**: WebRTC 미디어 처리(화상/음성 스트리밍)
- **내부 통신**:
    - OpenVidu 서버와 `8888` 포트로 WebSocket 통신
    - Coturn 서버와 협력하여 NAT 트래버설 수행
- **포트 사용 범위**:
    - 미디어 전용 포트: `40000-57000` (UDP)
    - ICE 후보자 교환용 포트: `57001-65535`
- **특징**:
    - 호스트 네트워크 사용
    - GPU 가속이 필요한 경우 추가 설정 필요
    - 크래시 로그는 `/opt/openvidu/kms-crashes` 저장

##### 1.4. coturn 컨테이너

- **역할**: TURN/STUN 서버 (NAT 트래버설 지원)
- **외부 노출 포트**:
    - TCP/UDP `3478` (기본 포트)
    - 미디어 릴레이 포트: `57001-65535` (UDP)
- **통신 방식**:
    - 모든 컨테이너에서 `COTURN_IP` 환경변수로 접근
    - 공유 비밀키(`COTURN_SHARED_SECRET_KEY`) 기반 인증
- **특징**:
    - WebRTC 피어 연결 시 최후의 수단(Last Resort)으로 사용
    - `--fingerprint` 옵션으로 보안 강화
    - ICE 후보자 생성에 관여

##### 1.5. openvidu-proxy (nginx)

- **역할**: 리버스 프록시 & SSL 종료점
- **외부 노출 포트**:
    - HTTP: `80` (환경변수 `HTTP_PORT` 설정 가능)
    - HTTPS: `443` (환경변수 `HTTPS_PORT` 설정 가능)
- **기능**
    - Let's Encrypt 인증서 자동 관리 (`/etc/letsencrypt` 볼륨)
    - 웹 애플리케이션(Dashboard) 호스팅
    - IP 화이트리싱(`ALLOWED_ACCESS_TO_*` 환경변수)
    - 사용자 요청 → OpenVidu 서버 라우팅
- **특징**
    - `custom-nginx-*` 볼륨으로 Nginx 설정 확장 가능
    - HSTS, Modern Cipher Suite 지원

###### 1.5.1. nginx conf 파일

- 컨테이너 내부로 들어가자 (`docker -i -t 0d06b422cea5 /bin/bash`)
- `/etc/nginx/nginx.conf` -> 이 파일은 비어있다. 다른 곳에 설정파일이 있을 것이다.
- `/etc/nginx/conf.d/default.conf`

```nginx
upstream yourapp {
    server localhost:5442;
}

upstream openviduserver {
    server localhost:5443;
}

server {
    listen 80;
    listen [::]:80;
    server_name opvd.chocolate-letter.com;

    # Redirect to https
    location / {
        rewrite ^(.*) https://opvd.chocolate-letter.com:443$1 permanent;
    }

    # letsencrypt
    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location /nginx_status {
        stub_status;
        allow 127.0.0.1;  # only allow requests from localhost
        deny all;         # deny all other hosts
    }
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name opvd.chocolate-letter.com;

    # SSL Config
    ssl_certificate         /etc/letsencrypt/live/opvd.chocolate-letter.com/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/opvd.chocolate-letter.com/privkey.pem;
    ssl_trusted_certificate /etc/letsencrypt/live/opvd.chocolate-letter.com/fullchain.pem;
    ssl_session_cache shared:SSL:50m;
    ssl_session_timeout 5m;
    ssl_stapling on;
    ssl_stapling_verify on;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers "ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384";
    ssl_prefer_server_ciphers off;
    add_header Strict-Transport-Security "max-age=63072000" always;

    # Proxy
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header X-Forwarded-Proto https;
    proxy_headers_hash_bucket_size 512;
    proxy_redirect off;

    # Websockets
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";

    # Your App
    location / {
        proxy_pass http://yourapp; # Openvidu call by default
    }

    ########################
    # OpenVidu Locations   #
    ########################

    #################################
    # Common rules CE              #
    #################################

    # Dashboard rule
    location /dashboard {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    # Websocket rule
    location ~ /openvidu$ {
        proxy_pass http://openviduserver;
    }

    #################################
    # New API                       #
    #################################

    location /openvidu/layouts {
        rewrite ^/openvidu/layouts/(.*)$ /custom-layout/$1 break;
        root /opt/openvidu;
    }

    location /openvidu/recordings {
        proxy_pass http://openviduserver;
    }

    location /openvidu/api {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    location /openvidu/info {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    location /openvidu/accept-certificate {
        proxy_pass http://openviduserver;
    }

    location /openvidu/cdr {
        allow all;
        deny all;
        proxy_pass http://openviduserver;
    }

    #################################
    # LetsEncrypt                   #
    #################################

    location /.well-known/acme-challenge {
        root /var/www/certbot;
        try_files $uri $uri/ =404;
    }
}
```

### 1/27 (월)
---